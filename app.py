import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import warnings
import os
from matplotlib.font_manager import FontProperties
import matplotlib.font_manager as fm
import re

# å…¨å±€è®¾ç½®
warnings.filterwarnings('ignore')
plt.rcParams['axes.unicode_minus'] = False  # æå‰è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# å®šä¹‰å…¨å±€å­—ä½“å¯¹è±¡
font_prop = None

def setup_chinese_font():
    """ä¼˜åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®ï¼Œå¢åŠ æ›´å¤šå¤‡ç”¨å­—ä½“"""
    global font_prop
    # ä¼˜å…ˆå°è¯•çš„å­—ä½“åˆ—è¡¨
    font_paths = [
        os.path.join(os.path.dirname(os.path.abspath(__file__)), "SourceHanSansSC-Regular.otf"),
        os.path.join(os.path.dirname(os.path.abspath(__file__)), "SimHei.ttf"),
        os.path.join(os.path.dirname(os.path.abspath(__file__)), "Microsoft YaHei.ttf")
    ]
    
    # ç³»ç»Ÿå†…ç½®å¤‡ç”¨å­—ä½“
    system_fonts = ['WenQuanYi Micro Hei', 'DejaVu Sans', 'SimHei', 'Microsoft YaHei']
    
    # å°è¯•åŠ è½½æœ¬åœ°å­—ä½“æ–‡ä»¶
    for font_file in font_paths:
        if os.path.exists(font_file):
            try:
                font_prop = FontProperties(fname=font_file)
                # å…¨å±€è®¾ç½®å­—ä½“
                plt.rcParams["font.family"] = font_prop.get_name()
                sns.set(font=font_prop.get_name())
                st.success(f"æˆåŠŸåŠ è½½æœ¬åœ°å­—ä½“ï¼š{font_file}")
                return
            except Exception as e:
                st.warning(f"åŠ è½½å­—ä½“æ–‡ä»¶å¤±è´¥ï¼š{e}")
                continue
    
    # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
    for font_name in system_fonts:
        try:
            font_prop = FontProperties(family=font_name)
            plt.rcParams['font.sans-serif'] = [font_name]
            sns.set(font=font_name)
            st.info(f"ä½¿ç”¨ç³»ç»Ÿå¤‡ç”¨å­—ä½“ï¼š{font_name}")
            return
        except Exception:
            continue
    
    # æœ€ç»ˆå…œåº•
    st.warning("æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å¯¼è‡´ä¸­æ–‡æ˜¾ç¤ºå¼‚å¸¸")
    font_prop = FontProperties(family='DejaVu Sans')
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']

# è°ƒç”¨å­—ä½“è®¾ç½®
setup_chinese_font()

# åŠ è½½æƒ…æ„Ÿè¯å…¸
@st.cache_data
def load_sentiment_dictionaries():
    """åŠ è½½æƒ…æ„Ÿè¯å…¸ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pos_dict_path = os.path.join(script_dir, 'zhang_unformal_pos (1).txt')
    neg_dict_path = os.path.join(script_dir, 'zhang_unformal_neg (1).txt')
    
    # åˆå§‹åŒ–ç©ºåˆ—è¡¨
    positive_words = []
    negative_words = []
    
    # åŠ è½½ç§¯æè¯å…¸
    try:
        with open(pos_dict_path, 'r', encoding='utf-8') as f:
            positive_words = [line.strip() for line in f if line.strip()]
        st.success(f"æˆåŠŸåŠ è½½ç§¯æè¯å…¸ï¼Œå…±{len(positive_words)}ä¸ªè¯æ±‡")
    except FileNotFoundError:
        st.error(f"æœªæ‰¾åˆ°ç§¯æè¯å…¸æ–‡ä»¶ï¼š{pos_dict_path}")
    except Exception as e:
        st.error(f"åŠ è½½ç§¯æè¯å…¸å¤±è´¥ï¼š{e}")
    
    # åŠ è½½æ¶ˆæè¯å…¸
    try:
        with open(neg_dict_path, 'r', encoding='utf-8') as f:
            negative_words = [line.strip() for line in f if line.strip()]
        st.success(f"æˆåŠŸåŠ è½½æ¶ˆæè¯å…¸ï¼Œå…±{len(negative_words)}ä¸ªè¯æ±‡")
    except FileNotFoundError:
        st.error(f"æœªæ‰¾åˆ°æ¶ˆæè¯å…¸æ–‡ä»¶ï¼š{neg_dict_path}")
    except Exception as e:
        st.error(f"åŠ è½½æ¶ˆæè¯å…¸å¤±è´¥ï¼š{e}")
    
    return positive_words, negative_words

# ä¼˜åŒ–çš„æƒ…æ„Ÿåˆ†æå‡½æ•°
def lexicon_based_sentiment_analysis(text, pos_words, neg_words):
    """
    ä¼˜åŒ–çš„åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    é™ä½åˆ¤å®šé˜ˆå€¼ï¼Œå‡å°‘è¿‡åº¦ä¸­æ€§åŒ–
    """
    if pd.isna(text) or text.strip() == '':
        return 'ä¸­æ€§', 0.0
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
    text = str(text).strip()
    
    # è®¡ç®—æƒ…æ„Ÿè¯å‡ºç°æ¬¡æ•°
    pos_count = sum(1 for word in pos_words if word in text)
    neg_count = sum(1 for word in neg_words if word in text)
    
    # ä¼˜åŒ–å¾—åˆ†è®¡ç®—ï¼šé¿å…+1ç¨€é‡Šï¼Œç”¨maxé˜²æ­¢é™¤0
    total = max(pos_count + neg_count, 1)
    sentiment_score = (pos_count - neg_count) / total
    
    # é™ä½åˆ¤å®šé˜ˆå€¼ï¼Œå‡å°‘ä¸­æ€§æ¯”ä¾‹
    if sentiment_score > 0.05:
        sentiment_label = 'ç§¯æ'
    elif sentiment_score < -0.05:
        sentiment_label = 'æ¶ˆæ'
    else:
        sentiment_label = 'ä¸­æ€§'
    
    return sentiment_label, sentiment_score

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title('ğŸ“ˆ ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ')

# åŠ è½½æ•°æ®
@st.cache_data
def load_data(stock_code):
    """ä¼˜åŒ–çš„æ•°æ®åŠ è½½é€»è¾‘ï¼Œå¢åŠ æ–‡ä»¶æ£€æŸ¥"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    file_map = {
        "unified": os.path.join(script_dir, f"{stock_code}_sentiment_analysis_unified.csv"),
        "updated": os.path.join(script_dir, f"{stock_code}_sentiment_analysis_updated.csv"),
        "original": os.path.join(script_dir, f"{stock_code}_sentiment_analysis.csv")
    }
    
    # æ£€æŸ¥æ–‡ä»¶å¹¶åŠ è½½
    for file_type, file_path in file_map.items():
        if os.path.exists(file_path):
            try:
                comments_df = pd.read_csv(file_path)
                st.success(f"å·²åŠ è½½{file_type}æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
                break
            except Exception as e:
                st.error(f"åŠ è½½{file_type}æ–‡ä»¶å¤±è´¥ï¼š{e}")
                continue
    else:
        st.error("æœªæ‰¾åˆ°ä»»ä½•æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶")
        return pd.DataFrame(), pd.DataFrame()
    
    # åŠ è½½ä»·æ ¼æ•°æ®
    price_path = os.path.join(script_dir, f"{stock_code}_price_data.csv")
    try:
        price_df = pd.read_csv(price_path)
    except FileNotFoundError:
        st.error(f"æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®æ–‡ä»¶ï¼š{price_path}")
        price_df = pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½ä»·æ ¼æ•°æ®å¤±è´¥ï¼š{e}")
        price_df = pd.DataFrame()
    
    # å¤„ç†æ—¥æœŸåˆ—
    if not comments_df.empty:
        comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'], errors='coerce')
    if not price_df.empty:
        price_df['trade_date'] = pd.to_datetime(price_df['trade_date'], errors='coerce')
    
    return comments_df, price_df

# æ•°æ®å¤„ç†å‡½æ•°
def process_data(comments_df, price_df, text_length_limit=500, window_size=30, lag_days=0):
    """ä¼˜åŒ–çš„æ•°æ®å¤„ç†é€»è¾‘"""
    if comments_df.empty or price_df.empty:
        return pd.DataFrame(), pd.DataFrame()
    
    filtered_comments = comments_df.copy()
    
    # è°ƒæ•´æ–‡æœ¬å­—æ®µä¼˜å…ˆçº§
    text_fields = ['post_title', 'combined_text', 'processed_content']
    for field in text_fields:
        if field in filtered_comments.columns:
            filtered_comments['combined_text'] = filtered_comments[field]
            break
    
    # è¿‡æ»¤æ— æ•ˆè¯„è®ºï¼ˆä¼˜åŒ–æ­£åˆ™ï¼‰
    invalid_pattern = r'(å›¾ç‰‡å›¾ç‰‡|è½¬å‘è½¬å‘|^[!ï¼]{3,}$|^[?ï¼Ÿ]{3,}$|^\\.{3,}$|^\\s*$|^è½¬å‘$|^å›¾ç‰‡$)'
    filtered_comments = filtered_comments[~filtered_comments['combined_text'].astype(str).str.contains(invalid_pattern, na=True, regex=True)]
    
    # æƒ…æ„Ÿåˆ†æå¤„ç†
    if 'lexicon_sentiment' not in filtered_comments.columns or 'llm_sentiment_score' not in filtered_comments.columns:
        # åŠ è½½è¯å…¸å¹¶è®¡ç®—æƒ…æ„Ÿ
        positive_words, negative_words = load_sentiment_dictionaries()
        if positive_words and negative_words:
            sentiment_results = filtered_comments['combined_text'].apply(
                lambda x: lexicon_based_sentiment_analysis(x, positive_words, negative_words)
            )
            filtered_comments['llm_sentiment_label'] = sentiment_results.str[0]
            filtered_comments['llm_sentiment_score'] = sentiment_results.str[1]
            filtered_comments['ensemble_sentiment_score'] = sentiment_results.str[1]
            filtered_comments['lexicon_sentiment'] = sentiment_results.str[1]
        else:
            st.error("æƒ…æ„Ÿè¯å…¸åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
            return pd.DataFrame(), pd.DataFrame()
    else:
        # ç¡®ä¿æ ‡ç­¾åˆ—å­˜åœ¨ï¼ˆä¼˜åŒ–é˜ˆå€¼ï¼‰
        if 'llm_sentiment_label' not in filtered_comments.columns:
            def score_to_label(score):
                if score > 0.05:
                    return 'ç§¯æ'
                elif score < -0.05:
                    return 'æ¶ˆæ'
                else:
                    return 'ä¸­æ€§'
            filtered_comments['llm_sentiment_label'] = filtered_comments['llm_sentiment_score'].apply(score_to_label)
    
    # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
    filtered_comments['text_length'] = filtered_comments['combined_text'].astype(str).str.len()
    filtered_comments = filtered_comments[
        (filtered_comments['text_length'] >= 1) & 
        (filtered_comments['text_length'] <= text_length_limit)
    ]
    
    # æŒ‰æ—¥æœŸèšåˆæƒ…æ„Ÿæ•°æ®
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg(
        ensemble_mean=('ensemble_sentiment_score', 'mean'),
        ensemble_median=('ensemble_sentiment_score', 'median'),
        ensemble_std=('ensemble_sentiment_score', 'std'),
        comment_count=('ensemble_sentiment_score', 'count'),
        llm_mean=('llm_sentiment_score', 'mean'),
        lexicon_mean=('lexicon_sentiment', 'mean')
    ).reset_index()
    
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_median', 'ensemble_std', 
                              'comment_count', 'llm_mean', 'lexicon_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # åˆå¹¶ä»·æ ¼æ•°æ®
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    
    # å¡«å……ç¼ºå¤±å€¼
    fill_cols = ['comment_count', 'ensemble_mean', 'ensemble_median', 'ensemble_std', 'llm_mean', 'lexicon_mean']
    merged_df[fill_cols] = merged_df[fill_cols].fillna(0)
    
    # æ·»åŠ æ»åæ•°æ®
    if lag_days > 0:
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days).fillna(0)
        merged_df['comment_count_lag'] = merged_df['comment_count'].shift(lag_days).fillna(0)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std'].shift(lag_days).fillna(0)
    
    # ç§»åŠ¨å¹³å‡
    if window_size > 1:
        merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size, min_periods=1).mean()
        if 'next_day_return' in merged_df.columns:
            merged_df['next_day_return_rolling'] = merged_df['next_day_return'].rolling(window=window_size, min_periods=1).mean()
    
    return merged_df, filtered_comments

# ä¾§è¾¹æ è®¾ç½®
st.sidebar.header('âš™ï¸ å‚æ•°è®¾ç½®')

# è‚¡ç¥¨é€‰æ‹©
stock_code = st.sidebar.selectbox('é€‰æ‹©è‚¡ç¥¨ä»£ç ', ['300059'], index=0)
stock_name = 'ä¸œæ–¹è´¢å¯Œ'

# å‚æ•°è°ƒæ•´ï¼ˆä¼˜åŒ–é»˜è®¤å€¼ï¼‰
st.sidebar.subheader('åˆ†æå‚æ•°')
if 'params' not in st.session_state:
    st.session_state.params = {
        'text_length': 500,
        'window_size': 15,
        'lag_days': 1,
        'temperature': 0.1
    }

# é‡ç½®æŒ‰é’®
if st.sidebar.button('ğŸ”„ é‡ç½®å‚æ•°'):
    st.session_state.params = {
        'text_length': 500,
        'window_size': 15,
        'lag_days': 1,
        'temperature': 0.1
    }

# æ»‘å—è®¾ç½®
temperature = st.sidebar.slider(
    'LLMæ¸©åº¦å‚æ•°', 0.0, 1.0, 
    st.session_state.params['temperature'], 0.1, key='temp'
)
text_length = st.sidebar.slider(
    'æ–‡æœ¬é•¿åº¦é™åˆ¶', 50, 1000, 
    st.session_state.params['text_length'], 50, key='length'
)
window_size = st.sidebar.slider(
    'ç§»åŠ¨å¹³å‡çª—å£(å¤©)', 1, 90, 
    st.session_state.params['window_size'], 5, key='window'
)
lag_days = st.sidebar.slider(
    'æƒ…æ„Ÿæ»åå¤©æ•°', 0, 10, 
    st.session_state.params['lag_days'], 1, key='lag'
)

# æ›´æ–°session state
st.session_state.params.update({
    'text_length': text_length,
    'window_size': window_size,
    'lag_days': lag_days,
    'temperature': temperature
})

# ä¸»åˆ†æé€»è¾‘
try:
    # åŠ è½½æ•°æ®
    comments_df, price_df = load_data(stock_code)
    
    if comments_df.empty or price_df.empty:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    else:
        # å¤„ç†æ•°æ®
        merged_df, filtered_comments = process_data(
            comments_df, price_df, 
            text_length, window_size, lag_days
        )
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        st.header('ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥')
        col1, col2, col3, col4 = st.columns(4)
        
        total_comments = len(comments_df)
        filtered_count = len(filtered_comments)
        zero_sentiment = (filtered_comments['ensemble_sentiment_score'] == 0).sum()
        valid_days = len(merged_df[merged_df['comment_count'] > 0])
        
        with col1:
            st.metric("æ€»è¯„è®ºæ•°", total_comments)
        with col2:
            st.metric("æœ‰æ•ˆè¯„è®ºæ•°", filtered_count)
        with col3:
            st.metric("é›¶æƒ…æ„Ÿå¾—åˆ†è¯„è®º", zero_sentiment)
        with col4:
            st.metric("æœ‰è¯„è®ºçš„äº¤æ˜“æ—¥", valid_days)
        
        # è­¦å‘Šæç¤º
        if filtered_count / total_comments < 0.5:
            st.warning(f"âš ï¸ è¶…è¿‡50%çš„è¯„è®ºè¢«è¿‡æ»¤ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœ")
        if zero_sentiment / filtered_count > 0.8:
            st.warning(f"âš ï¸ è¶…è¿‡80%çš„æœ‰æ•ˆè¯„è®ºæƒ…æ„Ÿå¾—åˆ†ä¸º0ï¼Œæƒ…æ„ŸåŒºåˆ†åº¦è¾ƒä½")
        
        # è¯„è®ºæ•°é‡è¶‹åŠ¿
        st.header('ğŸ“ è¯„è®ºæ•°é‡åˆ†æ')
        try:
            daily_comments = comments_df.groupby(comments_df['post_publish_time'].dt.date)['post_id'].count()
            
            fig, ax = plt.subplots(figsize=(12, 5))
            if not daily_comments.empty:
                daily_comments.plot(ax=ax, marker='o', linewidth=2, markersize=4, color='#2E86AB')
                ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡å˜åŒ–è¶‹åŠ¿', fontproperties=font_prop, fontsize=14)
                ax.set_xlabel('æ—¥æœŸ', fontproperties=font_prop)
                ax.set_ylabel('è¯„è®ºæ•°é‡', fontproperties=font_prop)
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                stats_text = f'å¹³å‡ï¼š{daily_comments.mean():.1f}æ¡\næœ€é«˜ï¼š{daily_comments.max()}æ¡\næœ€ä½ï¼š{daily_comments.min()}æ¡'
                ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, 
                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),
                        fontproperties=font_prop)
                
                plt.xticks(rotation=45, fontproperties=font_prop)
                plt.yticks(fontproperties=font_prop)
            else:
                ax.text(0.5, 0.5, 'æš‚æ— è¯„è®ºæ•°æ®', transform=ax.transAxes, 
                        ha='center', va='center', fontproperties=font_prop, fontsize=12)
            
            plt.tight_layout()
            st.pyplot(fig)
        except Exception as e:
            st.error(f"ç»˜åˆ¶è¯„è®ºè¶‹åŠ¿å›¾å¤±è´¥ï¼š{e}")
        
        # æƒ…æ„Ÿåˆ†æç»“æœ
        st.header('â¤ï¸ æƒ…æ„Ÿåˆ†æç»“æœ')
        col1, col2 = st.columns(2)
        
        # æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ
        with col1:
            st.subheader('æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ')
            try:
                sentiment_counts = filtered_comments['llm_sentiment_label'].value_counts()
                
                fig, ax = plt.subplots(figsize=(8, 6))
                colors = {'ç§¯æ': '#27AE60', 'ä¸­æ€§': '#F39C12', 'æ¶ˆæ': '#E74C3C'}
                wedges, texts, autotexts = ax.pie(
                    sentiment_counts.values,
                    labels=sentiment_counts.index,
                    colors=[colors.get(l, '#95A5A6') for l in sentiment_counts.index],
                    autopct='%1.1f%%',
                    startangle=90,
                    explode=(0.05, 0.05, 0.05)
                )
                
                # è®¾ç½®é¥¼å›¾å­—ä½“
                for text in texts + autotexts:
                    text.set_fontproperties(font_prop)
                ax.set_title('LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ', fontproperties=font_prop, fontsize=14)
                
                st.pyplot(fig)
                # æ˜¾ç¤ºè¯¦ç»†æ•°æ®
                st.write("è¯¦ç»†ç»Ÿè®¡ï¼š")
                for label, count in sentiment_counts.items():
                    st.write(f"- {label}ï¼š{count}æ¡ ({count/len(filtered_comments)*100:.1f}%)")
            except Exception as e:
                st.error(f"ç»˜åˆ¶æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾å¤±è´¥ï¼š{e}")
        
        # æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
        with col2:
            st.subheader('æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
            try:
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.histplot(
                    filtered_comments['ensemble_sentiment_score'],
                    bins=30,
                    kde=True,
                    ax=ax,
                    color='#3498DB',
                    edgecolor='white'
                )
                
                # æ·»åŠ ç»Ÿè®¡çº¿
                mean_score = filtered_comments['ensemble_sentiment_score'].mean()
                median_score = filtered_comments['ensemble_sentiment_score'].median()
                ax.axvline(mean_score, color='red', linestyle='--', label=f'å‡å€¼: {mean_score:.3f}')
                ax.axvline(median_score, color='green', linestyle='--', label=f'ä¸­ä½æ•°: {median_score:.3f}')
                
                # è®¾ç½®æ ‡ç­¾
                ax.set_title('èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ', fontproperties=font_prop, fontsize=14)
                ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontproperties=font_prop)
                ax.set_ylabel('è¯„è®ºæ•°é‡', fontproperties=font_prop)
                ax.legend(prop=font_prop)
                ax.grid(True, alpha=0.3)
                
                plt.xticks(fontproperties=font_prop)
                plt.yticks(fontproperties=font_prop)
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write("å¾—åˆ†ç»Ÿè®¡ï¼š")
                st.write(f"- å‡å€¼ï¼š{mean_score:.4f}")
                st.write(f"- ä¸­ä½æ•°ï¼š{median_score:.4f}")
                st.write(f"- æ ‡å‡†å·®ï¼š{filtered_comments['ensemble_sentiment_score'].std():.4f}")
            except Exception as e:
                st.error(f"ç»˜åˆ¶æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒå›¾å¤±è´¥ï¼š{e}")
        
        # æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»
        st.header('ğŸ“ˆ æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»åˆ†æ')
        try:
            if 'next_day_return' in merged_df.columns and not merged_df.empty:
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # å‡†å¤‡æ•°æ®
                if lag_days > 0 and 'ensemble_mean_lag' in merged_df.columns:
                    x_data = merged_df['ensemble_mean_lag']
                    x_label = f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†(æ»å{lag_days}å¤©)'
                else:
                    x_data = merged_df['ensemble_mean']
                    x_label = 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†'
                
                y_data = merged_df['next_day_return']
                valid_mask = x_data.notna() & y_data.notna()
                x_valid = x_data[valid_mask]
                y_valid = y_data[valid_mask]
                
                if len(x_valid) > 0:
                    # ç»˜åˆ¶æ•£ç‚¹å›¾
                    colors = ['#E74C3C' if x < -0.05 else '#27AE60' if x > 0.05 else '#F39C12' for x in x_valid]
                    ax.scatter(x_valid, y_valid, c=colors, alpha=0.6, s=50)
                    
                    # çº¿æ€§å›å½’
                    if len(x_valid) >= 2:
                        X = x_valid.values.reshape(-1, 1)
                        model = LinearRegression()
                        model.fit(X, y_valid)
                        r2 = model.score(X, y_valid)
                        
                        # ç»˜åˆ¶å›å½’çº¿
                        x_line = np.linspace(x_valid.min(), x_valid.max(), 100).reshape(-1, 1)
                        y_line = model.predict(x_line)
                        ax.plot(x_line, y_line, 'r--', linewidth=2, label=f'å›å½’çº¿ (RÂ²={r2:.3f})')
                    
                    ax.set_title(f'æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³»', fontproperties=font_prop, fontsize=14)
                    ax.set_xlabel(x_label, fontproperties=font_prop)
                    ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡ (%)', fontproperties=font_prop)
                    ax.legend(prop=font_prop)
                    ax.grid(True, alpha=0.3)
                    
                    plt.xticks(fontproperties=font_prop)
                    plt.yticks(fontproperties=font_prop)
                else:
                    ax.text(0.5, 0.5, 'æš‚æ— æœ‰æ•ˆæ•°æ®', transform=ax.transAxes, 
                            ha='center', va='center', fontproperties=font_prop, fontsize=12)
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # å›å½’åˆ†æ
                st.subheader('ğŸ“Š å›å½’åˆ†æç»“æœ')
                if len(x_valid) >= 3:
                    # å¤šå˜é‡å›å½’
                    try:
                        if lag_days > 0:
                            features = ['ensemble_mean_lag', 'comment_count_lag', 'ensemble_std_lag']
                        else:
                            features = ['ensemble_mean', 'comment_count', 'ensemble_std']
                        
                        # ç¡®ä¿ç‰¹å¾åˆ—å­˜åœ¨
                        features = [f for f in features if f in merged_df.columns]
                        X = merged_df[features][valid_mask]
                        y = merged_df['next_day_return'][valid_mask]
                        
                        model = LinearRegression()
                        model.fit(X, y)
                        r2 = model.score(X, y)
                        
                        st.write(f"**å¤šå˜é‡çº¿æ€§å›å½’ (RÂ² = {r2:.4f})**")
                        st.write(f"æˆªè·ï¼š{model.intercept_:.4f}")
                        for i, feat in enumerate(features):
                            st.write(f"{feat} ç³»æ•°ï¼š{model.coef_[i]:.4f}")
                    except Exception as e:
                        st.info(f"å¤šå˜é‡å›å½’å¤±è´¥ï¼Œå°è¯•å•å˜é‡å›å½’ï¼š{e}")
                        
                        # å•å˜é‡å›å½’
                        X_simple = x_valid.values.reshape(-1, 1)
                        model_simple = LinearRegression()
                        model_simple.fit(X_simple, y_valid)
                        r2_simple = model_simple.score(X_simple, y_valid)
                        
                        st.write(f"**å•å˜é‡çº¿æ€§å›å½’ (RÂ² = {r2_simple:.4f})**")
                        st.write(f"æˆªè·ï¼š{model_simple.intercept_:.4f}")
                        st.write(f"æƒ…æ„Ÿå¾—åˆ†ç³»æ•°ï¼š{model_simple.coef_[0]:.4f}")
            else:
                st.warning("æ•°æ®ä¸­ç¼ºå°‘æ¬¡æ—¥æ”¶ç›Šç‡åˆ—ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
        except Exception as e:
            st.error(f"åˆ†ææƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»å¤±è´¥ï¼š{e}")
        
        # è¯„è®ºç¤ºä¾‹
        st.header('ğŸ” è¯„è®ºç¤ºä¾‹')
        selected_sentiment = st.selectbox('é€‰æ‹©æƒ…æ„Ÿç±»å‹', ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ'])
        sentiment_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == selected_sentiment]
        
        if len(sentiment_comments) > 0:
            sample_comments = sentiment_comments[['post_publish_time', 'combined_text']].sample(min(10, len(sentiment_comments)))
            st.dataframe(sample_comments, use_container_width=True)
        else:
            st.info(f"æœªæ‰¾åˆ°{selected_sentiment}æƒ…æ„Ÿçš„è¯„è®ºç¤ºä¾‹")
        
        # å‚æ•°å½±å“åˆ†æ
        st.header('ğŸ“‹ å‚æ•°å½±å“åˆ†æ')
        st.write(f"- **æ–‡æœ¬é•¿åº¦é™åˆ¶**ï¼š{text_length}å­—ç¬¦ï¼Œè¿‡æ»¤æ‰{len(comments_df)-len(filtered_comments)}æ¡è¶…é•¿/è¶…çŸ­è¯„è®º")
        st.write(f"- **ç§»åŠ¨å¹³å‡çª—å£**ï¼š{window_size}å¤©ï¼Œç”¨äºå¹³æ»‘æƒ…æ„Ÿå’Œæ”¶ç›Šç‡æ•°æ®")
        st.write(f"- **æƒ…æ„Ÿæ»åå¤©æ•°**ï¼š{lag_days}å¤©ï¼Œåˆ†æ{lag_days}å¤©å‰çš„æƒ…æ„Ÿå¯¹å½“æ—¥æ”¶ç›Šç‡çš„å½±å“")
        st.write(f"- **LLMæ¸©åº¦å‚æ•°**ï¼š{temperature}ï¼Œå€¼è¶Šé«˜ç”Ÿæˆçš„æƒ…æ„Ÿåˆ†æç»“æœè¶Šå¤šæ ·")
        
except Exception as e:
    st.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™ï¼š{str(e)}")
    st.info("è¯·æ£€æŸ¥ï¼š1. æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ 2. è¯å…¸æ–‡ä»¶æ˜¯å¦æ­£ç¡® 3. ä¾èµ–åº“æ˜¯å¦å®‰è£…å®Œæ•´")

# é¡µè„š
st.markdown("---")
st.markdown("Â© 2025 ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æå·¥å…· | åŸºäºStreamlitå¼€å‘")
