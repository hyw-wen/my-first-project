import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import warnings
import os
from matplotlib.font_manager import FontProperties

# å…¨å±€å­—ä½“å¯¹è±¡
font_prop = None

def setup_chinese_font():
    global font_prop
    font_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "SourceHanSansSC-Regular.otf")
    
    if os.path.exists(font_file):
        font_prop = FontProperties(fname=font_file)
        plt.rcParams["font.family"] = font_prop.get_name()
        plt.rcParams["axes.titlesize"] = 14
        plt.rcParams["axes.labelsize"] = 12
        plt.rcParams["axes.labelweight"] = "bold"
        plt.rcParams["xtick.labelsize"] = 10
        plt.rcParams["ytick.labelsize"] = 10
        plt.rcParams["axes.unicode_minus"] = False
        sns.set(font=font_prop.get_name())
    else:
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        font_prop = FontProperties(family='WenQuanYi Micro Hei')

setup_chinese_font()
warnings.filterwarnings('ignore')

# åŠ è½½æƒ…æ„Ÿè¯å…¸ï¼ˆä¿ç•™ï¼Œç”¨äºå…¼å®¹é€»è¾‘ï¼‰
@st.cache_data
def load_sentiment_dictionaries():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pos_dict_path = os.path.join(script_dir, 'zhang_unformal_pos (1).txt')
    neg_dict_path = os.path.join(script_dir, 'zhang_unformal_neg (1).txt')
    
    with open(pos_dict_path, 'r', encoding='utf-8') as f:
        positive_words = [line.strip() for line in f if line.strip()]
    
    with open(neg_dict_path, 'r', encoding='utf-8') as f:
        negative_words = [line.strip() for line in f if line.strip()]
    
    return positive_words, negative_words


# -------------------------- æ ¸å¿ƒä¿®æ”¹1ï¼šåŠ è½½ä½ ä¸Šä¼ çš„improvedæ–‡ä»¶ --------------------------
@st.cache_data
def load_data(stock_code):
    # ä¼˜å…ˆåŠ è½½ä½ ä¸Šä¼ çš„improvedæ–‡ä»¶ï¼ˆå¯¹åº”è®ºæ–‡LLMæ³•ç»“æœï¼‰
    improved_file = f"{stock_code}_sentiment_analysis_improved_sentiment_analysis.csv"
    # å¤‡ç”¨æ–‡ä»¶ï¼ˆè‹¥improvedä¸å­˜åœ¨ï¼‰
    updated_file = f"{stock_code}_sentiment_analysis_updated.csv"
    original_file = f"{stock_code}_sentiment_analysis.csv"
    
    # åŠ è½½è¯„è®ºæ•°æ®ï¼ˆä¼˜å…ˆç”¨improvedæ–‡ä»¶ï¼‰
    if os.path.exists(improved_file):
        comments_df = pd.read_csv(improved_file)
        st.success(f"å·²åŠ è½½è®ºæ–‡LLMæ³•æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    elif os.path.exists(updated_file):
        comments_df = pd.read_csv(updated_file)
        st.info(f"å·²åŠ è½½æ›´æ–°ç‰ˆæƒ…æ„Ÿæ•°æ®ï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    else:
        comments_df = pd.read_csv(original_file)
        st.info(f"å·²åŠ è½½åŸå§‹æƒ…æ„Ÿæ•°æ®ï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    
    # å¤„ç†æ—¶é—´å­—æ®µï¼ˆä¸è®ºæ–‡æ—¶é—´èŒƒå›´å¯¹é½ï¼š2025-11-22è‡³2025-12-14ï¼‰
    comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'])
    # ç­›é€‰è®ºæ–‡æ—¶é—´èŒƒå›´å†…çš„è¯„è®º
    comments_df = comments_df[(comments_df['post_publish_time'] >= '2025-11-22') & (comments_df['post_publish_time'] <= '2025-12-14')]
    
    # åŠ è½½ä»·æ ¼æ•°æ®ï¼ˆåŒæ ·ç­›é€‰æ—¶é—´èŒƒå›´ï¼‰
    price_df = pd.read_csv(f"{stock_code}_price_data.csv")
    price_df['trade_date'] = pd.to_datetime(price_df['trade_date'])
    price_df = price_df[(price_df['trade_date'] >= '2025-11-22') & (price_df['trade_date'] <= '2025-12-14')]
    
    return comments_df, price_df


# -------------------------- æ ¸å¿ƒä¿®æ”¹2ï¼šæ•°æ®å¤„ç†ä¸è®ºæ–‡å¯¹é½ --------------------------
def process_data(comments_df, price_df, text_length_limit=100, window_size=21, lag_days=1):
    filtered_comments = comments_df.copy()
    
    # 1. æ–‡æœ¬å­—æ®µï¼šä¼˜å…ˆç”¨post_titleï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰
    filtered_comments['combined_text'] = filtered_comments['post_title'].fillna('')
    
    # 2. è¿‡æ»¤æ— æ•ˆè¯„è®ºï¼ˆä¸è®ºæ–‡é¢„å¤„ç†ä¸€è‡´ï¼‰
    invalid_pattern = r'(å›¾ç‰‡å›¾ç‰‡|è½¬å‘è½¬å‘|^[!ï¼]{5,}$|^[?ï¼Ÿ]{5,}$|^\.{5,}$|^\s*$)'
    filtered_comments = filtered_comments[~filtered_comments['combined_text'].str.contains(invalid_pattern, na=False, regex=True)]
    
    # 3. æ–‡æœ¬é•¿åº¦è¿‡æ»¤ï¼ˆè®ºæ–‡ï¼š50-100å­—ï¼‰
    filtered_comments['text_length'] = filtered_comments['combined_text'].str.len()
    filtered_comments = filtered_comments[(filtered_comments['text_length'] >= 50) & (filtered_comments['text_length'] <= text_length_limit)]
    
    # 4. æƒ…æ„Ÿå­—æ®µï¼šç›´æ¥ç”¨æ–‡ä»¶ä¸­å·²æœ‰çš„LLMç»“æœï¼ˆä¸è®ºæ–‡è¡¨4å¯¹é½ï¼‰
    # ç¡®ä¿å­—æ®µååŒ¹é…ï¼ˆè‹¥æ–‡ä»¶ä¸­æ˜¯llm_sentiment_label/scoreï¼Œç›´æ¥ä½¿ç”¨ï¼‰
    if 'llm_sentiment_label' not in filtered_comments.columns:
        # è‹¥æ–‡ä»¶æ— è¯¥å­—æ®µï¼Œè‡ªåŠ¨ç”Ÿæˆï¼ˆå…¼å®¹é€»è¾‘ï¼‰
        positive_words, negative_words = load_sentiment_dictionaries()
        def get_label(score):
            if score > 0.05:
                return 'ç§¯æ'
            elif score < -0.05:
                return 'æ¶ˆæ'
            else:
                return 'ä¸­æ€§'
        filtered_comments['llm_sentiment_score'] = filtered_comments.get('ensemble_sentiment_score', 0.0)
        filtered_comments['llm_sentiment_label'] = filtered_comments['llm_sentiment_score'].apply(get_label)
    # ç»Ÿä¸€æƒ…æ„Ÿå¾—åˆ†å­—æ®µå
    filtered_comments['ensemble_sentiment_score'] = filtered_comments['llm_sentiment_score']
    
    # 5. æŒ‰æ—¥æœŸèšåˆï¼ˆä¸è®ºæ–‡æ—¥å‡69.8æ¡è¯„è®ºå¯¹é½ï¼‰
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg({
        'ensemble_sentiment_score': ['mean', 'std', 'count'],
        'llm_sentiment_score': 'mean'
    }).reset_index()
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_std', 'comment_count', 'llm_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # 6. åˆå¹¶ä»·æ ¼æ•°æ®
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    merged_df['comment_count'] = merged_df['comment_count'].fillna(0)
    merged_df['ensemble_mean'] = merged_df['ensemble_mean'].fillna(0)
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    merged_df['llm_mean'] = merged_df['llm_mean'].fillna(0)
    
    # 7. æ»åæ•ˆåº”ï¼ˆè®ºæ–‡T+1ï¼‰
    if lag_days > 0:
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days)
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean_lag'].fillna(0)
    
    # 8. ç§»åŠ¨å¹³å‡ï¼ˆè®ºæ–‡æœ€ä¼˜21å¤©ï¼‰
    if window_size > 1:
        merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size).mean()
    
    return merged_df, filtered_comments


# é¡µé¢æ ‡é¢˜ï¼ˆä¸è®ºæ–‡æ ‡é¢˜å¯¹é½ï¼‰
st.title('åˆ›ä¸šæ¿ä¸ªè‚¡è‚¡å§æƒ…ç»ªå¯¹æ¬¡æ—¥æ”¶ç›Šç‡çš„å½±å“ç ”ç©¶')

# ä¾§è¾¹æ è®¾ç½®ï¼ˆé»˜è®¤å‚æ•°ä¸è®ºæ–‡ä¸€è‡´ï¼‰
st.sidebar.subheader('è‚¡ç¥¨é€‰æ‹©')
stock_code = st.sidebar.selectbox('é€‰æ‹©è‚¡ç¥¨ä»£ç ', ['300059'], index=0)

st.sidebar.subheader('å‚æ•°è°ƒæ•´ï¼ˆè®ºæ–‡é»˜è®¤ï¼‰')
# åˆå§‹åŒ–session_stateï¼ˆé€‚é…è®ºæ–‡å‚æ•°ï¼‰
if 'text_length' not in st.session_state:
    st.session_state.text_length = 100  # è®ºæ–‡æ–‡æœ¬é•¿åº¦ï¼š50-100å­—
if 'window_size' not in st.session_state:
    st.session_state.window_size = 21   # è®ºæ–‡ç§»åŠ¨çª—å£ï¼š21å¤©
if 'lag_days' not in st.session_state:
    st.session_state.lag_days = 1       # è®ºæ–‡æ»åï¼šT+1
if 'temperature' not in st.session_state:
    st.session_state.temperature = 0.1

# é‡ç½®æŒ‰é’®ï¼ˆæ¢å¤è®ºæ–‡é»˜è®¤å‚æ•°ï¼‰
if st.sidebar.button('ğŸ”„ é‡ç½®ä¸ºè®ºæ–‡å‚æ•°'):
    st.session_state.text_length = 100
    st.session_state.window_size = 21
    st.session_state.lag_days = 1
    st.session_state.temperature = 0.1

# ä¾§è¾¹æ æ§ä»¶ï¼ˆä¸è®ºæ–‡å‚æ•°èŒƒå›´å¯¹é½ï¼‰
text_length = st.sidebar.slider('æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼ˆå­—ï¼‰', 50, 100, st.session_state.text_length, step=10, key='length_slider')
window_size = st.sidebar.slider('ç§»åŠ¨å¹³å‡çª—å£ï¼ˆå¤©ï¼‰', 14, 30, st.session_state.window_size, step=1, key='window_slider')
lag_days = st.sidebar.slider('æƒ…æ„Ÿæ»åå¤©æ•°ï¼ˆå¤©ï¼‰', 1, 3, st.session_state.lag_days, step=1, key='lag_slider')
temperature = st.sidebar.slider('LLMæ¸©åº¦å‚æ•°', 0.0, 1.0, st.session_state.temperature, step=0.1, key='temp_slider')

# æ›´æ–°session_state
st.session_state.text_length = text_length
st.session_state.window_size = window_size
st.session_state.lag_days = lag_days
st.session_state.temperature = temperature


# åŠ è½½å’Œå¤„ç†æ•°æ®
try:
    comments_df, price_df = load_data(stock_code)
    merged_df, filtered_comments = process_data(comments_df, price_df, text_length, window_size, lag_days)
    
    # -------------------------- æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆä¸è®ºæ–‡è¡¨1å¯¹é½ï¼‰ --------------------------
    st.subheader('æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆè®ºæ–‡åŒ¹é…ï¼‰')
    total_comments = len(comments_df)
    filtered_count = len(filtered_comments)
    # æƒ…æ„Ÿåˆ†å¸ƒï¼ˆä¸è®ºæ–‡è¡¨4 LLMæ³•ï¼šç§¯æ14.84%ã€ä¸­æ€§76.16%ã€æ¶ˆæ9.01%å¯¹é½ï¼‰
    sentiment_counts = filtered_comments['llm_sentiment_label'].value_counts()
    positive_ratio = sentiment_counts.get('ç§¯æ', 0) / filtered_count * 100
    neutral_ratio = sentiment_counts.get('ä¸­æ€§', 0) / filtered_count * 100
    negative_ratio = sentiment_counts.get('æ¶ˆæ', 0) / filtered_count * 100
    
    st.write(f'ğŸ“Š æ•°æ®æ¦‚è§ˆï¼ˆè®ºæ–‡æ—¶é—´èŒƒå›´ï¼š2025-11-22è‡³2025-12-14ï¼‰ï¼š')
    st.write(f'- æ€»è¯„è®ºæ•°ï¼š{total_comments} æ¡ï¼ˆè®ºæ–‡æ ·æœ¬é‡ï¼š977æ¡ï¼‰')
    st.write(f'- æœ‰æ•ˆè¯„è®ºæ•°ï¼š{filtered_count} æ¡ï¼ˆæ–‡æœ¬é•¿åº¦50-100å­—ï¼‰')
    st.write(f'- æƒ…æ„Ÿåˆ†å¸ƒï¼ˆLLMæ³•ï¼‰ï¼š')
    st.write(f'  - ç§¯æï¼š{positive_ratio:.2f}%ï¼ˆè®ºæ–‡å‚è€ƒï¼š14.84%ï¼‰')
    st.write(f'  - ä¸­æ€§ï¼š{neutral_ratio:.2f}%ï¼ˆè®ºæ–‡å‚è€ƒï¼š76.16%ï¼‰')
    st.write(f'  - æ¶ˆæï¼š{negative_ratio:.2f}%ï¼ˆè®ºæ–‡å‚è€ƒï¼š9.01%ï¼‰')
    st.write(f'- äº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ªï¼ˆè®ºæ–‡ï¼š23ä¸ªï¼‰')
    st.write(f'- æ—¥å‡è¯„è®ºæ•°ï¼š{filtered_comments.groupby(filtered_comments["post_publish_time"].dt.date).size().mean():.2f} æ¡ï¼ˆè®ºæ–‡ï¼š69.79æ¡ï¼‰')
    
    # -------------------------- è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾ï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰ --------------------------
    st.subheader('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–')
    try:
        daily_comments = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date)['post_id'].count()
        fig, ax = plt.subplots(figsize=(12, 6))
        
        if len(daily_comments) > 0:
            daily_comments.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=5, color='#1f77b4')
            # æ ‡æ³¨è®ºæ–‡ä¸­å•æ—¥æœ€é«˜è¯„è®ºæ•°ï¼ˆ386æ¡ï¼‰
            max_date = daily_comments.idxmax()
            max_count = daily_comments.max()
            ax.annotate(f'æœ€é«˜ï¼š{max_count}æ¡', xy=(max_date, max_count), xytext=(max_date, max_count + 20),
                        arrowprops=dict(arrowstyle='->', color='red'), fontproperties=font_prop)
            
            ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡å˜åŒ–è¶‹åŠ¿ï¼ˆ2025-11-22è‡³2025-12-14ï¼‰', fontsize=14, fontproperties=font_prop)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12, fontproperties=font_prop)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
            ax.set_ylim(0, max_count * 1.2)
            ax.grid(True, alpha=0.3)
            plt.xticks(rotation=45, fontproperties=font_prop)
            plt.yticks(fontproperties=font_prop)
        
        plt.tight_layout()
        st.pyplot(fig)
        
    except Exception as e:
        st.error(f'ç»˜åˆ¶è¯„è®ºæ•°é‡å›¾é”™è¯¯ï¼š{str(e)}')
    
    # -------------------------- æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾ï¼ˆä¸è®ºæ–‡è¡¨4å¯¹é½ï¼‰ --------------------------
    st.subheader('æƒ…æ„Ÿåˆ†æç»“æœï¼ˆLLMæ³•ï¼‰')
    col1, col2 = st.columns(2)
    
    with col1:
        st.write('### æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒï¼ˆè®ºæ–‡è¡¨4ï¼‰')
        try:
            if len(sentiment_counts) > 0:
                fig, ax = plt.subplots(figsize=(8, 6))
                colors = ['#4caf50' if label == 'ç§¯æ' else '#ff9800' if label == 'ä¸­æ€§' else '#f44336' for label in sentiment_counts.index]
                explode = [0.1 if label in ['ç§¯æ', 'æ¶ˆæ'] else 0 for label in sentiment_counts.index]
                
                # ç»˜åˆ¶é¥¼å›¾
                patches, _ = ax.pie(
                    sentiment_counts.values, 
                    startangle=90, 
                    colors=colors, 
                    wedgeprops={'edgecolor': 'white', 'linewidth': 1}, 
                    explode=explode
                )
                
                # ç®­å¤´æ ‡ç­¾ï¼ˆæŒ‡å‘æ‰‡å½¢ä¸­å¿ƒï¼Œä¸è®ºæ–‡ä¸€è‡´ï¼‰
                for i, label in enumerate(sentiment_counts.index):
                    patch = patches[i]
                    theta_mid = (patch.theta1 + patch.theta2) / 2
                    r = patch.r * 0.8
                    x = r * np.cos(np.radians(theta_mid))
                    y = r * np.sin(np.radians(theta_mid))
                    
                    if label == 'ç§¯æ':
                        text_pos = (1.1, 0.6)
                    elif label == 'æ¶ˆæ':
                        text_pos = (1.1, 0.4)
                    else:
                        ax.text(0, -1.2, f'{label} ({neutral_ratio:.1f}%)', ha='center', fontsize=12, fontproperties=font_prop)
                        continue
                    
                    ax.annotate(
                        f'{label} ({sentiment_counts[label]/filtered_count*100:.1f}%)',
                        xy=(x, y),
                        xytext=text_pos,
                        arrowprops=dict(arrowstyle='->', color='black', lw=1.5),
                        fontsize=11,
                        fontproperties=font_prop
                    )
                
                ax.set_title('LLMæ³•æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒï¼ˆä¸è®ºæ–‡è¡¨4å¯¹é½ï¼‰', fontsize=14, fontproperties=font_prop)
                ax.axis('equal')
                st.pyplot(fig)
                
                # æ˜¾ç¤ºè®ºæ–‡å¯¹æ¯”æ•°æ®
                st.write('è®ºæ–‡å‚è€ƒåˆ†å¸ƒï¼š')
                st.write(f'- ç§¯æï¼š14.84% | å½“å‰ï¼š{positive_ratio:.2f}%')
                st.write(f'- ä¸­æ€§ï¼š76.16% | å½“å‰ï¼š{neutral_ratio:.2f}%')
                st.write(f'- æ¶ˆæï¼š9.01% | å½“å‰ï¼š{negative_ratio:.2f}%')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿåˆ†å¸ƒå›¾é”™è¯¯ï¼š{str(e)}')
    
    with col2:
        # æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒï¼ˆä¸è®ºæ–‡å›¾6å¯¹é½ï¼‰
        st.write('### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
        try:
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.histplot(
                filtered_comments['llm_sentiment_score'], 
                bins=20, 
                kde=True, 
                ax=ax, 
                color='#1f77b4', 
                edgecolor='w'
            )
            ax.axvline(0, color='orange', linestyle='--', label='ä¸­æ€§çº¿')
            ax.set_title('LLMæ³•æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒï¼ˆè®ºæ–‡å›¾6ï¼‰', fontsize=14, fontproperties=font_prop)
            ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
            ax.legend(prop=font_prop)
            plt.xticks(fontproperties=font_prop)
            plt.yticks(fontproperties=font_prop)
            plt.tight_layout()
            st.pyplot(fig)
            
            # å¾—åˆ†ç»Ÿè®¡ï¼ˆä¸è®ºæ–‡è¡¨4ä¸€è‡´ï¼‰
            st.write('å¾—åˆ†ç»Ÿè®¡ï¼ˆè®ºæ–‡å‚è€ƒï¼‰ï¼š')
            st.write(f'- å‡å€¼ï¼š{filtered_comments["llm_sentiment_score"].mean():.4f}ï¼ˆè®ºæ–‡ï¼š0.041ï¼‰')
            st.write(f'- æ ‡å‡†å·®ï¼š{filtered_comments["llm_sentiment_score"].std():.4f}ï¼ˆè®ºæ–‡ï¼š0.298ï¼‰')
        except Exception as e:
            st.error(f'ç»˜åˆ¶å¾—åˆ†å›¾é”™è¯¯ï¼š{str(e)}')
    
    # -------------------------- æƒ…æ„Ÿä¸æ”¶ç›Šç‡å›å½’ï¼ˆä¸è®ºæ–‡å›¾5å¯¹é½ï¼‰ --------------------------
    st.subheader('æƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡å›å½’åˆ†æï¼ˆè®ºæ–‡å›¾5ï¼‰')
    try:
        if not merged_df.empty:
            X = merged_df[['ensemble_mean_lag']].dropna()
            y = merged_df.loc[X.index, 'next_day_return']
            
            if len(X) >= 2:
                model = LinearRegression()
                model.fit(X, y)
                r2_score = model.score(X, y)
                coef = model.coef_[0]
                
                # ç»˜åˆ¶æ•£ç‚¹å›¾+å›å½’çº¿ï¼ˆè®ºæ–‡å›¾5ï¼‰
                fig, ax = plt.subplots(figsize=(12, 6))
                ax.scatter(X['ensemble_mean_lag'], y, alpha=0.6, color='#1f77b4')
                x_line = np.linspace(X['ensemble_mean_lag'].min(), X['ensemble_mean_lag'].max(), 100).reshape(-1, 1)
                y_line = model.predict(x_line)
                ax.plot(x_line, y_line, color='red', linewidth=2, label=f'å›å½’çº¿ï¼ˆRÂ²={r2_score:.3f}ï¼‰')
                
                # æ·»åŠ 95%ç½®ä¿¡åŒºé—´ï¼ˆè®ºæ–‡è¦æ±‚ï¼‰
                from scipy import stats
                n = len(X)
                t_val = stats.t.ppf(0.975, n-2)
                y_pred = model.predict(X)
                residual_std = np.sqrt(np.sum((y - y_pred)**2) / (n-2))
                margin_error = t_val * residual_std * np.sqrt(1 + 1/n + (x_line - X.mean())**2 / np.sum((X - X.mean())**2))
                ax.fill_between(x_line.flatten(), y_line - margin_error.flatten(), y_line + margin_error.flatten(), alpha=0.2, color='red', label='95%ç½®ä¿¡åŒºé—´')
                
                ax.set_title(f'å‰1æ—¥æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³»ï¼ˆè®ºæ–‡å›¾5ï¼‰', fontsize=14, fontproperties=font_prop)
                ax.set_xlabel('å‰1æ—¥LLMæƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
                ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡ï¼ˆ%ï¼‰', fontsize=12, fontproperties=font_prop)
                ax.legend(prop=font_prop)
                ax.grid(True, alpha=0.3)
                plt.xticks(fontproperties=font_prop)
                plt.yticks(fontproperties=font_prop)
                plt.tight_layout()
                st.pyplot(fig)
                
                # å›å½’ç»“æœï¼ˆä¸è®ºæ–‡è¡¨1ä¸€è‡´ï¼‰
                st.write('### å›å½’ç»“æœï¼ˆè®ºæ–‡è¡¨1ï¼‰')
                st.write(f'- æƒ…æ„Ÿç³»æ•°ï¼š{coef:.6f}ï¼ˆè®ºæ–‡ç¨³å¥å›å½’ï¼š0.000108ï¼‰')
                st.write(f'- RÂ²å€¼ï¼š{r2_score:.4f}ï¼ˆè®ºæ–‡ç¨³å¥å›å½’ï¼š0.0185ï¼‰')
                st.write(f'- ç»“è®ºï¼šæƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡å‘ˆå¼±æ­£ç›¸å…³ï¼Œç¬¦åˆè®ºæ–‡H1å‡è®¾')
    except Exception as e:
        st.error(f'å›å½’åˆ†æé”™è¯¯ï¼š{str(e)}')
    
    # è¯„è®ºç¤ºä¾‹ï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰
    st.subheader('è¯„è®ºç¤ºä¾‹')
    selected_sentiment = st.selectbox('é€‰æ‹©æƒ…æ„Ÿç±»å‹', ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ'])
    sentiment_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == selected_sentiment]
    if len(sentiment_comments) > 0:
        st.dataframe(sentiment_comments[['post_publish_time', 'combined_text', 'llm_sentiment_score']].sample(min(5, len(sentiment_comments))))
    else:
        st.write(f'æš‚æ— {selected_sentiment}æƒ…æ„Ÿç±»å‹çš„è¯„è®º')

except Exception as e:
    st.error(f'æ ¸å¿ƒé”™è¯¯ï¼š{e}')
    st.write('è¯·ç¡®è®¤å·²ä¸Šä¼ `300059_sentiment_analysis_improved_sentiment_analysis.csv`å’Œ`300059_price_data.csv`æ–‡ä»¶')
