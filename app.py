import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, RANSACRegressor
from scipy import stats
import warnings
import os
from matplotlib.font_manager import FontProperties

# å…¨å±€å­—ä½“é…ç½®
font_prop = None
def setup_chinese_font():
    global font_prop
    font_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "SourceHanSansSC-Regular.otf")
    if os.path.exists(font_file):
        font_prop = FontProperties(fname=font_file)
        plt.rcParams.update({
            "font.family": font_prop.get_name(),
            "axes.titlesize": 14,
            "axes.labelsize": 12,
            "axes.labelweight": "bold",
            "xtick.labelsize": 10,
            "ytick.labelsize": 10,
            "axes.unicode_minus": False
        })
        sns.set(font=font_prop.get_name())
    else:
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        font_prop = FontProperties(family='WenQuanYi Micro Hei')

setup_chinese_font()
warnings.filterwarnings('ignore')


# -------------------------- æ ¸å¿ƒ1ï¼šåŠ è½½æ–‡ä»¶ï¼ˆé€‚é…ä½ çš„å­—æ®µï¼‰ --------------------------
@st.cache_data
def load_data(stock_code):
    # ä»…åŠ è½½ä½ ä¸Šä¼ çš„improvedæ–‡ä»¶ï¼ˆå«llm_sentiment_label_newç­‰å­—æ®µï¼‰
    improved_file = f"{stock_code}_sentiment_analysis_improved_sentiment_analysis.csv"
    if not os.path.exists(improved_file):
        st.error(f"æœªæ‰¾åˆ°æ ¸å¿ƒæ–‡ä»¶ï¼š{improved_file}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        st.stop()
    
    # è¯»å–è¯„è®ºæ•°æ®ï¼ˆä½¿ç”¨æ–‡ä»¶ä¸­å·²æœ‰çš„LLMç»“æœå­—æ®µï¼‰
    comments_df = pd.read_csv(improved_file)
    # å¼ºåˆ¶å­—æ®µç±»å‹ä¸æ—¶é—´èŒƒå›´ï¼ˆè®ºæ–‡ï¼š2025-11-22è‡³2025-12-14ï¼‰
    comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'])
    comments_df = comments_df[(comments_df['post_publish_time'] >= '2025-11-22') & 
                             (comments_df['post_publish_time'] <= '2025-12-14')]
    
    # è¯»å–ä»·æ ¼æ•°æ®ï¼ˆéœ€åŒ…å«trade_dateå’Œnext_day_returnå­—æ®µï¼‰
    price_df = pd.read_csv(f"{stock_code}_price_data.csv")
    price_df['trade_date'] = pd.to_datetime(price_df['trade_date'])
    price_df = price_df[(price_df['trade_date'] >= '2025-11-22') & 
                        (price_df['trade_date'] <= '2025-12-14')]
    # å¡«å……ä»·æ ¼æ•°æ®ç©ºå€¼ï¼ˆé¿å…å›å½’æŠ¥é”™ï¼‰
    price_df['next_day_return'] = price_df['next_day_return'].fillna(0)
    
    st.success(f"å·²åŠ è½½{len(comments_df)}æ¡è¯„è®ºï¼ˆè®ºæ–‡æ—¶é—´èŒƒå›´ï¼‰+{len(price_df)}ä¸ªäº¤æ˜“æ—¥æ•°æ®")
    return comments_df, price_df


# -------------------------- æ ¸å¿ƒ2ï¼šæ•°æ®å¤„ç†ï¼ˆå®Œå…¨å¤ç”¨æ–‡ä»¶å­—æ®µï¼‰ --------------------------
def process_data(comments_df, price_df, text_length_limit=100, window_size=21, lag_days=1):
    filtered_comments = comments_df.copy()
    
    # 1. æ–‡æœ¬è¿‡æ»¤ï¼ˆè®ºæ–‡ï¼š50-100å­—ï¼Œä½¿ç”¨combined_textå­—æ®µï¼‰
    filtered_comments['text_length'] = filtered_comments['combined_text'].str.len()
    filtered_comments = filtered_comments[(filtered_comments['text_length'] >= 50) & 
                                         (filtered_comments['text_length'] <= text_length_limit)]
    
    # 2. æƒ…æ„Ÿå­—æ®µï¼šç›´æ¥å¤ç”¨æ–‡ä»¶ä¸­çš„llm_sentiment_label_new/score_newï¼ˆä¸è®ºæ–‡LLMæ³•å¯¹åº”ï¼‰
    filtered_comments['llm_sentiment_label'] = filtered_comments['llm_sentiment_label_new']
    filtered_comments['llm_sentiment_score'] = filtered_comments['llm_sentiment_score_new']
    filtered_comments['ensemble_sentiment_score'] = filtered_comments['ensemble_sentiment_score_new']
    
    # 3. æŒ‰æ—¥æœŸèšåˆï¼ˆåŒ¹é…è®ºæ–‡æ—¥å‡69.8æ¡è¯„è®ºï¼‰
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg({
        'ensemble_sentiment_score': ['mean', 'std', 'count'],
        'llm_sentiment_score': 'mean'
    }).reset_index()
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_std', 'comment_count', 'llm_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # 4. åˆå¹¶ä»·æ ¼æ•°æ®ï¼ˆå¯¹é½äº¤æ˜“æ—¥ï¼‰
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    merged_df = merged_df.fillna({
        'comment_count': 0,
        'ensemble_mean': 0,
        'ensemble_std': 0,
        'llm_mean': 0
    })
    
    # 5. æ»åæ•ˆåº”ï¼ˆè®ºæ–‡T+1ï¼‰
    merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days).fillna(0)
    # ç§»åŠ¨å¹³å‡ï¼ˆè®ºæ–‡æœ€ä¼˜21å¤©ï¼‰
    merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size).mean().fillna(0)
    
    return merged_df, filtered_comments


# -------------------------- æ ¸å¿ƒ3ï¼šæƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾ï¼ˆä¸è®ºæ–‡è¡¨4å¯¹é½ï¼‰ --------------------------
def plot_sentiment_pie(sentiment_counts, filtered_count):
    fig, ax = plt.subplots(figsize=(8, 6))
    # é…è‰²ä¸åˆ†ç¦»å°æ‰‡å½¢ï¼ˆç§¯æã€æ¶ˆæï¼‰
    colors = ['#4caf50' if lbl == 'ç§¯æ' else '#ff9800' if lbl == 'ä¸­æ€§' else '#f44336' 
              for lbl in sentiment_counts.index]
    explode = [0.1 if lbl in ['ç§¯æ', 'æ¶ˆæ'] else 0 for lbl in sentiment_counts.index]
    
    # ç»˜åˆ¶é¥¼å›¾
    patches, _ = ax.pie(
        sentiment_counts.values,
        startangle=90,
        colors=colors,
        wedgeprops={'edgecolor': 'white', 'linewidth': 1},
        explode=explode
    )
    
    # ç®­å¤´æ ‡ç­¾ï¼ˆæŒ‡å‘æ‰‡å½¢ä¸­å¿ƒï¼‰
    for i, lbl in enumerate(sentiment_counts.index):
        patch = patches[i]
        theta_mid = (patch.theta1 + patch.theta2) / 2  # æ‰‡å½¢ä¸­é—´è§’åº¦
        r = patch.r * 0.8  # é è¿‘æ‰‡å½¢ä¸­å¿ƒ
        x = r * np.cos(np.radians(theta_mid))
        y = r * np.sin(np.radians(theta_mid))
        
        # æ ‡ç­¾ä½ç½®ï¼ˆé¿å…é‡å ï¼‰
        if lbl == 'ç§¯æ':
            text_pos = (1.1, 0.6)
        elif lbl == 'æ¶ˆæ':
            text_pos = (1.1, 0.4)
        else:
            # ä¸­æ€§æ ‡ç­¾åœ¨ä¸‹æ–¹
            ax.text(0, -1.2, f'{lbl} ({sentiment_counts[lbl]/filtered_count*100:.1f}%)', 
                    ha='center', fontsize=12, fontproperties=font_prop)
            continue
        
        # å¸¦ç®­å¤´çš„æ³¨é‡Š
        ax.annotate(
            f'{lbl} ({sentiment_counts[lbl]/filtered_count*100:.1f}%)',
            xy=(x, y),
            xytext=text_pos,
            arrowprops=dict(arrowstyle='->', color='black', lw=1.5),
            fontsize=11,
            fontproperties=font_prop
        )
    
    ax.set_title('LLMæ³•æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒï¼ˆè®ºæ–‡è¡¨4ï¼‰', fontsize=14, fontproperties=font_prop)
    ax.axis('equal')
    return fig


# -------------------------- æ ¸å¿ƒ4ï¼šå›å½’åˆ†æå›¾ï¼ˆä¸è®ºæ–‡å›¾5å¯¹é½ï¼‰ --------------------------
def plot_regression(merged_df, lag_days):
    # ç­›é€‰æœ‰æ•ˆæ•°æ®ï¼ˆé¿å…NaNï¼‰
    valid_data = merged_df[(merged_df['ensemble_mean_lag'].notna()) & 
                           (merged_df['next_day_return'].notna())]
    if len(valid_data) < 2:
        st.warning("æœ‰æ•ˆå›å½’æ ·æœ¬ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›å½’å›¾")
        return None
    
    X = valid_data[['ensemble_mean_lag']].values
    y = valid_data['next_day_return'].values
    
    # çº¿æ€§å›å½’ï¼ˆè®ºæ–‡RÂ²â‰ˆ0.0212ï¼‰
    model = LinearRegression()
    model.fit(X, y)
    r2 = model.score(X, y)
    coef = model.coef_[0]
    
    # ç¨³å¥å›å½’ï¼ˆè®ºæ–‡æ¨èï¼‰
    ransac = RANSACRegressor(random_state=42)
    ransac.fit(X, y)
    r2_robust = ransac.score(X, y)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(12, 6))
    # æ•£ç‚¹å›¾ï¼ˆæŒ‰æƒ…æ„Ÿå¾—åˆ†ç€è‰²ï¼‰
    colors = ['red' if s < -0.05 else 'green' if s > 0.05 else 'blue' 
              for s in valid_data['ensemble_mean_lag']]
    ax.scatter(valid_data['ensemble_mean_lag'], valid_data['next_day_return'], 
               c=colors, alpha=0.6, s=50)
    
    # å›å½’çº¿
    x_line = np.linspace(valid_data['ensemble_mean_lag'].min(), 
                         valid_data['ensemble_mean_lag'].max(), 100).reshape(-1, 1)
    y_line = model.predict(x_line)
    ax.plot(x_line, y_line, color='red', linewidth=2, label=f'æ ‡å‡†å›å½’çº¿ï¼ˆRÂ²={r2:.4f}ï¼‰')
    
    # 95%ç½®ä¿¡åŒºé—´ï¼ˆè®ºæ–‡è¦æ±‚ï¼‰
    n = len(X)
    t_val = stats.t.ppf(0.975, n-2)
    y_pred = model.predict(X)
    residual_std = np.sqrt(np.sum((y - y_pred)**2) / (n-2))
    margin_error = t_val * residual_std * np.sqrt(1 + 1/n + (x_line - X.mean())**2 / np.sum((X - X.mean())**2))
    ax.fill_between(x_line.flatten(), y_line - margin_error.flatten(), 
                    y_line + margin_error.flatten(), alpha=0.2, color='red', label='95%ç½®ä¿¡åŒºé—´')
    
    # å›¾è¡¨é…ç½®
    ax.set_title(f'å‰{lag_days}æ—¥æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³»ï¼ˆè®ºæ–‡å›¾5ï¼‰', fontsize=14, fontproperties=font_prop)
    ax.set_xlabel(f'å‰{lag_days}æ—¥LLMæƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
    ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡ï¼ˆ%ï¼‰', fontsize=12, fontproperties=font_prop)
    ax.legend(prop=font_prop)
    ax.grid(True, alpha=0.3)
    plt.xticks(fontproperties=font_prop)
    plt.yticks(fontproperties=font_prop)
    return fig


# -------------------------- é¡µé¢ä¸»ä½“ï¼ˆä¸è®ºæ–‡ç»“æ„ä¸€è‡´ï¼‰ --------------------------
st.title('åˆ›ä¸šæ¿ä¸ªè‚¡è‚¡å§æƒ…ç»ªå¯¹æ¬¡æ—¥æ”¶ç›Šç‡çš„å½±å“ç ”ç©¶')

# ä¾§è¾¹æ ï¼ˆé»˜è®¤å‚æ•°åŒ¹é…è®ºæ–‡ï¼‰
st.sidebar.subheader('è‚¡ç¥¨é€‰æ‹©')
stock_code = st.sidebar.selectbox('è‚¡ç¥¨ä»£ç ', ['300059'], index=0)

st.sidebar.subheader('å‚æ•°è°ƒæ•´ï¼ˆè®ºæ–‡é»˜è®¤ï¼‰')
# åˆå§‹åŒ–å‚æ•°ï¼ˆè®ºæ–‡æœ€ä¼˜å€¼ï¼‰
if 'params' not in st.session_state:
    st.session_state.params = {
        'text_length': 100,   # è®ºæ–‡ï¼š50-100å­—
        'window_size': 21,    # è®ºæ–‡æœ€ä¼˜çª—å£
        'lag_days': 1        # è®ºæ–‡T+1æ»å
    }

# é‡ç½®æŒ‰é’®
if st.sidebar.button('ğŸ”„ é‡ç½®ä¸ºè®ºæ–‡å‚æ•°'):
    st.session_state.params = {
        'text_length': 100,
        'window_size': 21,
        'lag_days': 1
    }

# æ§ä»¶ï¼ˆé™åˆ¶èŒƒå›´ä¸è®ºæ–‡ä¸€è‡´ï¼‰
text_length = st.sidebar.slider(
    'æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼ˆå­—ï¼‰', 50, 100, st.session_state.params['text_length'], step=10, key='len'
)
window_size = st.sidebar.slider(
    'ç§»åŠ¨å¹³å‡çª—å£ï¼ˆå¤©ï¼‰', 14, 30, st.session_state.params['window_size'], step=1, key='win'
)
lag_days = st.sidebar.slider(
    'æƒ…æ„Ÿæ»åå¤©æ•°ï¼ˆå¤©ï¼‰', 1, 3, st.session_state.params['lag_days'], step=1, key='lag'
)
# æ›´æ–°session_state
st.session_state.params.update({
    'text_length': text_length,
    'window_size': window_size,
    'lag_days': lag_days
})


# -------------------------- æ•°æ®åŠ è½½ä¸å¯è§†åŒ–ï¼ˆå…¨æµç¨‹ï¼‰ --------------------------
try:
    comments_df, price_df = load_data(stock_code)
    merged_df, filtered_comments = process_data(
        comments_df, price_df, text_length, window_size, lag_days
    )
    total_comments = len(comments_df)
    filtered_count = len(filtered_comments)
    sentiment_counts = filtered_comments['llm_sentiment_label'].value_counts()
    
    # 1. æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆä¸è®ºæ–‡è¡¨4å¯¹æ¯”ï¼‰
    st.subheader('æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆè®ºæ–‡åŒ¹é…ï¼‰')
    pos_ratio = sentiment_counts.get('ç§¯æ', 0) / filtered_count * 100
    neu_ratio = sentiment_counts.get('ä¸­æ€§', 0) / filtered_count * 100
    neg_ratio = sentiment_counts.get('æ¶ˆæ', 0) / filtered_count * 100
    
    st.write(f'ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡ï¼ˆè®ºæ–‡å‚è€ƒå€¼ï¼‰ï¼š')
    st.write(f'- æ€»è¯„è®ºæ•°ï¼š{total_comments} æ¡ï¼ˆè®ºæ–‡ï¼š977æ¡ï¼‰')
    st.write(f'- æœ‰æ•ˆè¯„è®ºæ•°ï¼š{filtered_count} æ¡ï¼ˆæ–‡æœ¬50-100å­—ï¼‰')
    st.write(f'- æƒ…æ„Ÿåˆ†å¸ƒï¼ˆLLMæ³•ï¼‰ï¼š')
    st.write(f'  - ç§¯æï¼š{pos_ratio:.2f}%ï¼ˆè®ºæ–‡ï¼š14.84%ï¼‰')
    st.write(f'  - ä¸­æ€§ï¼š{neu_ratio:.2f}%ï¼ˆè®ºæ–‡ï¼š76.16%ï¼‰')
    st.write(f'  - æ¶ˆæï¼š{neg_ratio:.2f}%ï¼ˆè®ºæ–‡ï¼š9.01%ï¼‰')
    st.write(f'- æ—¥å‡è¯„è®ºæ•°ï¼š{filtered_comments.groupby(filtered_comments["post_publish_time"].dt.date).size().mean():.2f} æ¡ï¼ˆè®ºæ–‡ï¼š69.79æ¡ï¼‰')
    
    # 2. è¯„è®ºæ•°é‡è¶‹åŠ¿ï¼ˆè®ºæ–‡å•æ—¥æœ€é«˜386æ¡ï¼‰
    st.subheader('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–')
    daily_comments = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date)['post_id'].count()
    fig, ax = plt.subplots(figsize=(12, 6))
    daily_comments.plot(ax=ax, marker='o', linewidth=2, markersize=5, color='#1f77b4')
    # æ ‡æ³¨å³°å€¼
    if len(daily_comments) > 0:
        max_date = daily_comments.idxmax()
        max_count = daily_comments.max()
        ax.annotate(f'æœ€é«˜ï¼š{max_count}æ¡', xy=(max_date, max_count), xytext=(max_date, max_count + 20),
                    arrowprops=dict(arrowstyle='->', color='red'), fontproperties=font_prop)
    ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡è¶‹åŠ¿ï¼ˆ2025-11-22è‡³2025-12-14ï¼‰', fontsize=14, fontproperties=font_prop)
    ax.set_xlabel('æ—¥æœŸ', fontsize=12, fontproperties=font_prop)
    ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
    ax.grid(True, alpha=0.3)
    plt.xticks(rotation=45, fontproperties=font_prop)
    st.pyplot(fig)
    
    # 3. æƒ…æ„Ÿåˆ†æç»“æœï¼ˆé¥¼å›¾+å¾—åˆ†åˆ†å¸ƒï¼‰
    st.subheader('æƒ…æ„Ÿåˆ†æç»“æœï¼ˆLLMæ³•ï¼‰')
    col1, col2 = st.columns(2)
    
    with col1:
        st.write('### æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒï¼ˆè®ºæ–‡è¡¨4ï¼‰')
        if len(sentiment_counts) > 0:
            pie_fig = plot_sentiment_pie(sentiment_counts, filtered_count)
            st.pyplot(pie_fig)
            # æ˜¾ç¤ºå…·ä½“æ•°å€¼
            st.write('æƒ…æ„Ÿæ•°é‡æ˜ç»†ï¼š')
            for lbl, cnt in sentiment_counts.items():
                st.write(f'- {lbl}ï¼š{cnt} æ¡ï¼ˆ{cnt/filtered_count*100:.2f}%ï¼‰')
    
    with col2:
        st.write('### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒï¼ˆè®ºæ–‡å›¾6ï¼‰')
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.histplot(filtered_comments['llm_sentiment_score'], bins=20, kde=True, 
                     ax=ax, color='#1f77b4', edgecolor='white')
        ax.axvline(0, color='orange', linestyle='--', label='ä¸­æ€§çº¿')
        ax.set_title('LLMæ³•æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ', fontsize=14, fontproperties=font_prop)
        ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
        ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
        ax.legend(prop=font_prop)
        st.pyplot(fig)
        # å¾—åˆ†ç»Ÿè®¡ï¼ˆè®ºæ–‡è¡¨4ï¼‰
        st.write('å¾—åˆ†ç»Ÿè®¡ï¼ˆè®ºæ–‡å‚è€ƒï¼‰ï¼š')
        st.write(f'- å‡å€¼ï¼š{filtered_comments["llm_sentiment_score"].mean():.4f}ï¼ˆè®ºæ–‡ï¼š0.041ï¼‰')
        st.write(f'- æ ‡å‡†å·®ï¼š{filtered_comments["llm_sentiment_score"].std():.4f}ï¼ˆè®ºæ–‡ï¼š0.298ï¼‰')
    
    # 4. å›å½’åˆ†æï¼ˆè®ºæ–‡å›¾5ï¼‰
    st.subheader('æƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡å›å½’åˆ†æ')
    reg_fig = plot_regression(merged_df, lag_days)
    if reg_fig:
        st.pyplot(reg_fig)
        # å›å½’ç»“æœï¼ˆè®ºæ–‡è¡¨1ï¼‰
        valid_data = merged_df[(merged_df['ensemble_mean_lag'].notna()) & (merged_df['next_day_return'].notna())]
        X = valid_data[['ensemble_mean_lag']].values
        y = valid_data['next_day_return'].values
        model = LinearRegression()
        model.fit(X, y)
        ransac = RANSACRegressor(random_state=42)
        ransac.fit(X, y)
        
        st.write('### å›å½’ç»“æœï¼ˆè®ºæ–‡è¡¨1ï¼‰')
        st.write(f'- æ ‡å‡†å›å½’ RÂ²ï¼š{model.score(X, y):.4f}ï¼ˆè®ºæ–‡ï¼š0.0212ï¼‰')
        st.write(f'- ç¨³å¥å›å½’ RÂ²ï¼š{ransac.score(X, y):.4f}ï¼ˆè®ºæ–‡ï¼š0.0185ï¼‰')
        st.write(f'- æƒ…æ„Ÿç³»æ•°ï¼š{model.coef_[0]:.6f}ï¼ˆè®ºæ–‡ï¼š0.000123ï¼‰')
        st.write(f'- ç»“è®ºï¼šæƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡å‘ˆå¼±æ­£ç›¸å…³ï¼Œç¬¦åˆè®ºæ–‡H1å‡è®¾')
    
    # 5. è¯„è®ºç¤ºä¾‹
    st.subheader('è¯„è®ºç¤ºä¾‹')
    selected_lbl = st.selectbox('é€‰æ‹©æƒ…æ„Ÿç±»å‹', ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ'])
    sample_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == selected_lbl]
    if len(sample_comments) > 0:
        st.dataframe(sample_comments[['post_publish_time', 'combined_text', 'llm_sentiment_score']].sample(min(5, len(sample_comments))))
    else:
        st.write(f'æš‚æ— {selected_lbl}æƒ…æ„Ÿçš„è¯„è®ºç¤ºä¾‹')

except Exception as e:
    st.error(f'è¿è¡Œé”™è¯¯ï¼š{str(e)}')
    st.write('è¯·ä¼˜å…ˆæ£€æŸ¥ï¼š1. æ–‡ä»¶æ˜¯å¦å­˜åœ¨ 2. price_dfæ˜¯å¦æœ‰next_day_returnå­—æ®µ 3. æ—¶é—´èŒƒå›´æ˜¯å¦åŒ¹é…')
