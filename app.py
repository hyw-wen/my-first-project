import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, RANSACRegressor
import warnings
import os
from matplotlib.font_manager import FontProperties  # å¯¼å…¥å­—ä½“ç®¡ç†
import matplotlib.font_manager as fm

# å®šä¹‰å…¨å±€å­—ä½“å¯¹è±¡
font_prop = None

def setup_chinese_font():
    global font_prop  # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    font_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "SourceHanSansSC-Regular.otf")
    
    if os.path.exists(font_file):
        font_prop = FontProperties(fname=font_file)
        # å…¨å±€è®¾ç½®å­—ä½“
        plt.rcParams["font.family"] = font_prop.get_name()
        plt.rcParams["axes.titlesize"] = 14  # æ ‡é¢˜å¤§å°
        plt.rcParams["axes.labelsize"] = 12  # æ ‡ç­¾å¤§å°
        plt.rcParams["axes.labelweight"] = "bold"
        plt.rcParams["xtick.labelsize"] = 10
        plt.rcParams["ytick.labelsize"] = 10
        plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
        sns.set(font=font_prop.get_name())  # Seabornå­—ä½“è®¾ç½®
    else:
        st.error(f"æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼š{font_file}")
        # å¤‡ç”¨å­—ä½“è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        font_prop = FontProperties(family='WenQuanYi Micro Hei')

# è°ƒç”¨å­—ä½“è®¾ç½®å‡½æ•°
setup_chinese_font()

warnings.filterwarnings('ignore')

# åŠ è½½æƒ…æ„Ÿè¯å…¸
@st.cache_data
def load_sentiment_dictionaries():
    """
    åŠ è½½ç”¨æˆ·æä¾›çš„æƒ…æ„Ÿè¯å…¸
    ç§¯æè¯å…¸ï¼šzhang_unformal_pos (1).txt
    æ¶ˆæè¯å…¸ï¼šzhang_unformal_neg (1).txt
    """
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ„å»ºè¯å…¸æ–‡ä»¶è·¯å¾„
    pos_dict_path = os.path.join(script_dir, 'zhang_unformal_pos (1).txt')
    neg_dict_path = os.path.join(script_dir, 'zhang_unformal_neg (1).txt')
    
    # åŠ è½½ç§¯æè¯å…¸
    with open(pos_dict_path, 'r', encoding='utf-8') as f:
        positive_words = [line.strip() for line in f if line.strip()]
    
    # åŠ è½½æ¶ˆæè¯å…¸
    with open(neg_dict_path, 'r', encoding='utf-8') as f:
        negative_words = [line.strip() for line in f if line.strip()]
    
    return positive_words, negative_words

# å®ç°åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
def lexicon_based_sentiment_analysis(text, pos_words, neg_words):
    """
    åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    text: è¯„è®ºæ–‡æœ¬
    pos_words: ç§¯æè¯è¯­åˆ—è¡¨
    neg_words: æ¶ˆæè¯è¯­åˆ—è¡¨
    è¿”å›ï¼š
    - sentiment_label: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰
    - sentiment_score: æƒ…æ„Ÿå¾—åˆ†ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
    """
    if pd.isna(text) or text.strip() == '':
        return 'ä¸­æ€§', 0.0
    
    # è®¡ç®—ç§¯æè¯è¯­å’Œæ¶ˆæè¯è¯­çš„å‡ºç°æ¬¡æ•°
    pos_count = sum(1 for word in pos_words if word in text)
    neg_count = sum(1 for word in neg_words if word in text)
    
    # è®¡ç®—æƒ…æ„Ÿå¾—åˆ†
    total = pos_count + neg_count + 1  # åŠ 1é¿å…é™¤ä»¥0
    sentiment_score = (pos_count - neg_count) / total
    
    # ç¡®å®šæƒ…æ„Ÿæ ‡ç­¾
    if sentiment_score > 0.1:
        sentiment_label = 'ç§¯æ'
    elif sentiment_score < -0.1:
        sentiment_label = 'æ¶ˆæ'
    else:
        sentiment_label = 'ä¸­æ€§'
    
    return sentiment_label, sentiment_score

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title('ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ')

# åŠ è½½æ•°æ®
@st.cache_data
def load_data(stock_code):
    # åŠ è½½è¯„è®ºå’Œæƒ…æ„Ÿåˆ†ææ•°æ®
    # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€æƒ…æ„Ÿåˆ†æç»“æœæ–‡ä»¶
    unified_file = f"{stock_code}_sentiment_analysis_unified.csv"
    updated_file = f"{stock_code}_sentiment_analysis_updated.csv"
    original_file = f"{stock_code}_sentiment_analysis.csv"
    
    if os.path.exists(unified_file):
        comments_df = pd.read_csv(unified_file)
        st.success(f"å·²åŠ è½½ç»Ÿä¸€æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    elif os.path.exists(updated_file):
        comments_df = pd.read_csv(updated_file)
        st.info(f"å·²åŠ è½½æ”¹è¿›çš„æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    else:
        comments_df = pd.read_csv(original_file)
        st.warning(f"å·²åŠ è½½åŸå§‹æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
    
    comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'])
    
    # åŠ è½½ä»·æ ¼æ•°æ®
    price_df = pd.read_csv(f"{stock_code}_price_data.csv")
    price_df['trade_date'] = pd.to_datetime(price_df['trade_date'])
    
    return comments_df, price_df

# å¤„ç†æ•°æ®
def process_data(comments_df, price_df, text_length_limit=500, window_size=30, lag_days=0):
    # å¤„ç†combined_textå­—æ®µä¸ºç©ºçš„æƒ…å†µ
    filtered_comments = comments_df.copy()
    
    # è°ƒæ•´æ–‡æœ¬å­—æ®µä¼˜å…ˆçº§ï¼šä¼˜å…ˆä½¿ç”¨post_titleï¼ˆ977æ¡éç©ºï¼‰ï¼Œå†ä½¿ç”¨combined_textå’Œprocessed_content
    filtered_comments['combined_text'] = filtered_comments['post_title']
    
    # è¿‡æ»¤æ— æ•ˆè¯„è®ºå†…å®¹
    invalid_pattern = r'(å›¾ç‰‡å›¾ç‰‡|è½¬å‘è½¬å‘|^[!ï¼]{5,}$|^[?ï¼Ÿ]{5,}$|^\.{5,}$|^\s*$)'
    filtered_comments = filtered_comments[~filtered_comments['combined_text'].str.contains(invalid_pattern, na=False, regex=True)]
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«ç»Ÿä¸€æƒ…æ„Ÿåˆ†æç»“æœ
    if 'lexicon_sentiment' in filtered_comments.columns and 'llm_sentiment_score' in filtered_comments.columns:
        # å·²æœ‰ç»Ÿä¸€æƒ…æ„Ÿåˆ†æç»“æœï¼Œç›´æ¥ä½¿ç”¨
        # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„åˆ—éƒ½å­˜åœ¨
        if 'ensemble_sentiment_score' not in filtered_comments.columns:
            # å¦‚æœæ²¡æœ‰é›†æˆæ³•ç»“æœï¼Œä½¿ç”¨LLMæ³•ç»“æœ
            filtered_comments['ensemble_sentiment_score'] = filtered_comments['llm_sentiment_score']
        
        # ç¡®ä¿æƒ…æ„Ÿæ ‡ç­¾åˆ—å­˜åœ¨
        if 'llm_sentiment_label' not in filtered_comments.columns:
            # å¦‚æœæ²¡æœ‰æƒ…æ„Ÿæ ‡ç­¾ï¼Œæ ¹æ®å¾—åˆ†ç”Ÿæˆ
            def score_to_label(score):
                if score > 0.1:
                    return 'ç§¯æ'
                elif score < -0.1:
                    return 'æ¶ˆæ'
                else:
                    return 'ä¸­æ€§'
            
            filtered_comments['llm_sentiment_label'] = filtered_comments['llm_sentiment_score'].apply(score_to_label)
    else:
        # éœ€è¦è®¡ç®—æƒ…æ„Ÿåˆ†æç»“æœï¼ˆå‘åå…¼å®¹ï¼‰
        # åŠ è½½æƒ…æ„Ÿè¯å…¸
        positive_words, negative_words = load_sentiment_dictionaries()
        
        # åº”ç”¨åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
        sentiment_results = filtered_comments['combined_text'].apply(
            lambda x: lexicon_based_sentiment_analysis(x, positive_words, negative_words)
        )
        
        # å°†ç»“æœæ‹†åˆ†ä¸ºæƒ…æ„Ÿæ ‡ç­¾å’Œå¾—åˆ†åˆ—
        filtered_comments['llm_sentiment_label'] = sentiment_results.str[0]
        filtered_comments['llm_sentiment_score'] = sentiment_results.str[1]
        filtered_comments['ensemble_sentiment_score'] = sentiment_results.str[1]
        filtered_comments['lexicon_sentiment'] = sentiment_results.str[1]
    
    # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
    filtered_comments['text_length'] = filtered_comments['combined_text'].str.len()
    filtered_comments = filtered_comments[(filtered_comments['text_length'] >= 1) & (filtered_comments['text_length'] <= text_length_limit)]
    
    # æŒ‰æ—¥æœŸèšåˆæƒ…æ„Ÿæ•°æ®
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg({
        'ensemble_sentiment_score': ['mean', 'median', 'std', 'count'],
        'llm_sentiment_score': 'mean',
        'lexicon_sentiment': 'mean'
    }).reset_index()
    
    # é‡å‘½ååˆ—
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_median', 'ensemble_std', 'comment_count', 'llm_mean', 'lexicon_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # åˆå¹¶ä»·æ ¼æ•°æ®
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    
    # å¤„ç†æ²¡æœ‰è¯„è®ºçš„æ—¥æœŸï¼ˆå¡«å……NaNå€¼ï¼‰
    merged_df['comment_count'] = merged_df['comment_count'].fillna(0)
    merged_df['ensemble_mean'] = merged_df['ensemble_mean'].fillna(0)
    merged_df['ensemble_median'] = merged_df['ensemble_median'].fillna(0)
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    merged_df['llm_mean'] = merged_df['llm_mean'].fillna(0)
    merged_df['lexicon_mean'] = merged_df['lexicon_mean'].fillna(0)
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    
    # æ·»åŠ æ»åæƒ…æ„Ÿæ•°æ®
    if lag_days > 0:
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days)
        merged_df['comment_count_lag'] = merged_df['comment_count'].shift(lag_days)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std'].shift(lag_days)
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean_lag'].fillna(0)
        merged_df['comment_count_lag'] = merged_df['comment_count_lag'].fillna(0)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std_lag'].fillna(0)
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡
    if window_size > 1:
        merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size).mean()
        merged_df['next_day_return_rolling'] = merged_df['next_day_return'].rolling(window=window_size).mean()
    
    return merged_df, filtered_comments

# ä¾§è¾¹æ ï¼šè‚¡ç¥¨é€‰æ‹©ï¼ˆå›ºå®šä¸ºä¸œæ–¹è´¢å¯Œï¼‰
st.sidebar.subheader('è‚¡ç¥¨é€‰æ‹©')
stock_code = st.sidebar.selectbox('é€‰æ‹©è‚¡ç¥¨ä»£ç ', ['300059'], index=0)
stock_name = 'ä¸œæ–¹è´¢å¯Œ'

# ä¾§è¾¹æ ï¼šå‚æ•°è°ƒæ•´
st.sidebar.subheader('å‚æ•°è°ƒæ•´')

# ä½¿ç”¨session_stateç®¡ç†å‚æ•°çŠ¶æ€
if 'text_length' not in st.session_state:
    st.session_state.text_length = 500
if 'window_size' not in st.session_state:
    st.session_state.window_size = 30
if 'lag_days' not in st.session_state:
    st.session_state.lag_days = 0
if 'temperature' not in st.session_state:
    st.session_state.temperature = 0.1

# é‡ç½®æŒ‰é’®
if st.sidebar.button('ğŸ”„ é‡ç½®æ‰€æœ‰å‚æ•°'):
    st.session_state.text_length = 500
    st.session_state.window_size = 30
    st.session_state.lag_days = 0
    st.session_state.temperature = 0.1

temperature = st.sidebar.slider('LLMæ¸©åº¦å‚æ•°', 0.0, 1.0, st.session_state.temperature, step=0.1, key='temp_slider')
text_length = st.sidebar.slider('æ–‡æœ¬é•¿åº¦é™åˆ¶', 50, 1000, st.session_state.text_length, step=50, key='length_slider')
window_size = st.sidebar.slider('ç§»åŠ¨å¹³å‡çª—å£å¤§å°(å¤©)', 1, 90, st.session_state.window_size, step=5, key='window_slider')
lag_days = st.sidebar.slider('æƒ…æ„Ÿæ»åå¤©æ•°', 0, 10, st.session_state.lag_days, step=1, key='lag_slider')

# æ›´æ–°session_state
st.session_state.text_length = text_length
st.session_state.window_size = window_size
st.session_state.lag_days = lag_days
st.session_state.temperature = temperature

# åŠ è½½å’Œå¤„ç†æ•°æ®
try:
    comments_df, price_df = load_data(stock_code)
    merged_df, filtered_comments = process_data(comments_df, price_df, text_length, window_size, lag_days)
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    st.subheader('æ•°æ®è´¨é‡æ£€æŸ¥')
    
    # æ£€æŸ¥è¯„è®ºæ•°é‡
    total_comments = len(comments_df)
    filtered_count = len(filtered_comments)
    filtered_out_count = total_comments - filtered_count
    zero_sentiment = (comments_df['ensemble_sentiment_score'] == 0).sum()
    
    st.write(f'ğŸ“Š æ•°æ®æ¦‚è§ˆï¼š')
    st.write(f'- å…±æ”¶é›†åˆ° {total_comments} æ¡è¯„è®º')
    st.write(f'- ç»è¿‡è¿‡æ»¤åä¿ç•™ï¼š{filtered_count} æ¡æœ‰æ•ˆè¯„è®º')
    st.write(f'- è¿‡æ»¤æ‰çš„è¯„è®ºï¼š{filtered_out_count} æ¡ï¼ˆå†…å®¹æ— æ•ˆæˆ–ä¸ç¬¦åˆé•¿åº¦è¦æ±‚ï¼‰')
    st.write(f'- ä¸­æ€§æƒ…æ„Ÿè¯„è®ºï¼ˆåˆ†æ•°ä¸º0ï¼‰ï¼š{zero_sentiment} æ¡')
    st.write(f'- ä¿ç•™çš„äº¤æ˜“æ—¥æ•°æ®ï¼š{len(merged_df)} ä¸ª')
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    if filtered_count < total_comments * 0.5:
        st.warning(f'æ³¨æ„ï¼šæœ‰ {filtered_out_count} æ¡è¯„è®ºè¢«è¿‡æ»¤ï¼Œä¿ç•™çš„æœ‰æ•ˆæ ·æœ¬è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    if zero_sentiment > total_comments * 0.8:
        st.warning(f'æ³¨æ„ï¼š{zero_sentiment/total_comments:.1%} çš„è¯„è®ºæƒ…æ„Ÿåˆ†æ•°ä¸º0ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    # æ£€æŸ¥æ—¥æœŸèŒƒå›´
    if not merged_df.empty:
        date_range = f'{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}'
        st.write(f'- æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{date_range}')
    
    # æ˜¾ç¤ºè¯„è®ºæ•°é‡éšæ—¶é—´çš„å˜åŒ–
    st.subheader('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–')
    
    try:
        # æŒ‰æ—¥æœŸåˆ†ç»„å¹¶è®¡ç®—è¯„è®ºæ•°é‡
        daily_comments = comments_df.groupby(comments_df['post_publish_time'].dt.date)['post_id'].count()
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(daily_comments) > 0:
            # ç»˜åˆ¶æŠ˜çº¿å›¾
            daily_comments.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=5, color='#1f77b4')
            
            # æ·»åŠ æ¯æ—¥è¯„è®ºæ•°é‡æ ‡ç­¾
            for x, y in zip(daily_comments.index, daily_comments.values):
                ax.text(x, y + 0.5, str(y), ha='center', va='bottom', fontsize=9, fontproperties=font_prop)
            
            # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾ï¼ˆæ˜¾å¼æŒ‡å®šå­—ä½“ï¼‰
            ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡å˜åŒ–è¶‹åŠ¿', fontsize=14, fontproperties=font_prop)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12, fontproperties=font_prop)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
            
            # è°ƒæ•´Yè½´èŒƒå›´
            ax.set_ylim(0, daily_comments.max() * 1.1)
            
            # æ·»åŠ ç½‘æ ¼çº¿
            ax.grid(True, alpha=0.3)
            
            # è°ƒæ•´æ—¥æœŸæ ‡ç­¾
            plt.xticks(rotation=45, fontsize=10, fontproperties=font_prop)
            plt.yticks(fontproperties=font_prop)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_daily = daily_comments.mean()
            max_daily = daily_comments.max()
            min_daily = daily_comments.min()
            
            # åœ¨å›¾è¡¨ä¸­æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            stats_text = f'å¹³å‡æ—¥è¯„è®ºæ•°: {avg_daily:.1f}\næœ€é«˜æ—¥è¯„è®ºæ•°: {max_daily}\næœ€ä½æ—¥è¯„è®ºæ•°: {min_daily}'
            ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, 
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8), 
                    fontsize=10, fontproperties=font_prop)
        else:
            ax.set_title('æš‚æ— è¯„è®ºæ•°æ®', fontsize=14, fontproperties=font_prop)
            ax.text(0.5, 0.5, 'æ²¡æœ‰è¶³å¤Ÿçš„è¯„è®ºæ•°æ®æ¥ç»˜åˆ¶è¶‹åŠ¿å›¾', transform=ax.transAxes, 
                    ha='center', va='center', fontsize=12, fontproperties=font_prop)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.pyplot(fig)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if len(daily_comments) > 0:
            st.write(f'ğŸ“Š è¯„è®ºæ•°é‡ç»Ÿè®¡ï¼š')
            st.write(f'- è¯„è®ºæ—¥æœŸèŒƒå›´ï¼š{daily_comments.index.min()} è‡³ {daily_comments.index.max()}')
            st.write(f'- æœ‰è¯„è®ºçš„å¤©æ•°ï¼š{len(daily_comments)} å¤©')
            st.write(f'- å¹³å‡æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.mean():.1f} æ¡')
            st.write(f'- æœ€é«˜æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.max()} æ¡')
            st.write(f'- æœ€ä½æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.min()} æ¡')
        else:
            st.warning('æ²¡æœ‰è¯„è®ºæ•°æ®å¯æ˜¾ç¤ºã€‚')
    except Exception as e:
        st.error(f'ç»˜åˆ¶è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æç»“æœ
    st.subheader('æƒ…æ„Ÿåˆ†æç»“æœ')
    
    # æ·»åŠ æƒ…æ„Ÿåˆ†æç»Ÿè®¡è¡¨æ ¼
    if 'lexicon_sentiment' in comments_df.columns and 'llm_sentiment_score' in comments_df.columns and 'ensemble_sentiment_score' in comments_df.columns:
        st.write('### æƒ…æ„Ÿåˆ†ææ–¹æ³•æ¯”è¾ƒ')
        
        # è®¡ç®—ä¸‰ç§æ–¹æ³•çš„ç»Ÿè®¡æŒ‡æ ‡
        methods_stats = pd.DataFrame({
            'æ–¹æ³•': ['è¯å…¸æ³•', 'LLMæ³•', 'é›†æˆæ³•'],
            'å¹³å‡æƒ…æ„Ÿå¾—åˆ†': [
                comments_df['lexicon_sentiment'].mean(),
                comments_df['llm_sentiment_score'].mean(),
                comments_df['ensemble_sentiment_score'].mean()
            ],
            'æ ‡å‡†å·®': [
                comments_df['lexicon_sentiment'].std(),
                comments_df['llm_sentiment_score'].std(),
                comments_df['ensemble_sentiment_score'].std()
            ]
        })
        
        # è®¡ç®—ç§¯æã€ä¸­æ€§ã€æ¶ˆææ¯”ä¾‹
        if 'llm_sentiment_label' in comments_df.columns:
            sentiment_counts = comments_df['llm_sentiment_label'].value_counts()
            total_comments = len(comments_df)
            
            # è¯å…¸æ³•æ¯”ä¾‹ï¼ˆåŸºäºå¾—åˆ†è®¡ç®—ï¼‰
            lexicon_positive = (comments_df['lexicon_sentiment'] > 0.1).sum()
            lexicon_negative = (comments_df['lexicon_sentiment'] < -0.1).sum()
            lexicon_neutral = total_comments - lexicon_positive - lexicon_negative
            
            # LLMæ³•æ¯”ä¾‹ï¼ˆåŸºäºæ ‡ç­¾è®¡ç®—ï¼‰
            llm_positive = sentiment_counts.get('ç§¯æ', 0)
            llm_negative = sentiment_counts.get('æ¶ˆæ', 0)
            llm_neutral = sentiment_counts.get('ä¸­æ€§', 0)
            
            # é›†æˆæ³•æ¯”ä¾‹ï¼ˆåŸºäºå¾—åˆ†è®¡ç®—ï¼‰
            ensemble_positive = (comments_df['ensemble_sentiment_score'] > 0.1).sum()
            ensemble_negative = (comments_df['ensemble_sentiment_score'] < -0.1).sum()
            ensemble_neutral = total_comments - ensemble_positive - ensemble_negative
            
            # æ·»åŠ æ¯”ä¾‹åˆ—
            methods_stats['ç§¯ææ¯”ä¾‹'] = [
                f"{lexicon_positive/total_comments*100:.2f}%",
                f"{llm_positive/total_comments*100:.2f}%",
                f"{ensemble_positive/total_comments*100:.2f}%"
            ]
            methods_stats['ä¸­æ€§æ¯”ä¾‹'] = [
                f"{lexicon_neutral/total_comments*100:.2f}%",
                f"{llm_neutral/total_comments*100:.2f}%",
                f"{ensemble_neutral/total_comments*100:.2f}%"
            ]
            methods_stats['æ¶ˆææ¯”ä¾‹'] = [
                f"{lexicon_negative/total_comments*100:.2f}%",
                f"{llm_negative/total_comments*100:.2f}%",
                f"{ensemble_negative/total_comments*100:.2f}%"
            ]
        
        # æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼
        st.table(methods_stats.set_index('æ–¹æ³•'))
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write('### æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ')
        try:
            if 'llm_sentiment_label' in comments_df.columns:
                sentiment_counts = comments_df['llm_sentiment_label'].value_counts()
                
                if len(sentiment_counts) > 0:
                    fig, ax = plt.subplots(figsize=(8, 6))
                    colors = ['#4caf50' if label == 'ç§¯æ' else '#ff9800' if label == 'ä¸­æ€§' else '#f44336' for label in sentiment_counts.index]
                    explode = [0.1 if label in ['æ¶ˆæ', 'ç§¯æ'] else 0 for label in sentiment_counts.index]
                    
                    # ç»˜åˆ¶é¥¼å›¾ï¼Œä»…æ¥æ”¶æ‰‡å½¢å¯¹è±¡
                    patches, _ = ax.pie(
                        sentiment_counts.values, 
                        startangle=90, 
                        colors=colors, 
                        wedgeprops={'edgecolor': 'white', 'linewidth': 1}, 
                        explode=explode
                    )
                    
                    # éå†æ¯ä¸ªæ‰‡å½¢ï¼Œå•ç‹¬å¤„ç†â€œæ¶ˆæâ€â€œç§¯æâ€
                    for i, label in enumerate(sentiment_counts.index):
                        if label == 'æ¶ˆæ':
                            patch = patches[i]
                            # è®¡ç®—æ¶ˆææ‰‡å½¢çš„ä¸­é—´è§’åº¦
                            theta_mid = (patch.theta1 + patch.theta2) / 2
                            # è®¡ç®—æŒ‡å‘æ¶ˆæåŒºåŸŸä¸­å¿ƒçš„åæ ‡ï¼ˆåŠå¾„ç¼©å°ï¼Œæ›´é è¿‘å›¾è¡¨ï¼‰
                            r = patch.r * 0.9
                            x = r * np.cos(np.radians(theta_mid))
                            y = r * np.sin(np.radians(theta_mid))
                            # æ ‡ç­¾ä½ç½®é è¿‘å›¾è¡¨ï¼ˆxytextè°ƒæ•´ä¸ºæ›´ç´§å‡‘ï¼‰
                            ax.annotate(
                                f'æ¶ˆæ ({sentiment_counts[label]/len(comments_df)*100:.1f}%)',
                                xy=(x, y),  # ç®­å¤´æŒ‡å‘æ¶ˆæåŒºåŸŸä¸­å¿ƒ
                                xytext=(1.2, 0.7),  # æ ‡ç­¾é è¿‘å›¾è¡¨
                                arrowprops=dict(arrowstyle='->', color='black', lw=1.5),
                                fontsize=11,
                                fontproperties=font_prop
                            )
                        elif label == 'ç§¯æ':
                            patch = patches[i]
                            # è®¡ç®—ç§¯ææ‰‡å½¢çš„ä¸­é—´è§’åº¦
                            theta_mid = (patch.theta1 + patch.theta2) / 2
                            # è®¡ç®—æŒ‡å‘ç§¯æåŒºåŸŸä¸­å¿ƒçš„åæ ‡
                            r = patch.r * 0.9
                            x = r * np.cos(np.radians(theta_mid))
                            y = r * np.sin(np.radians(theta_mid))
                            # æ ‡ç­¾ä½ç½®ä¸æ¶ˆæé”™å¼€ï¼Œé è¿‘å›¾è¡¨
                            ax.annotate(
                                f'ç§¯æ ({sentiment_counts[label]/len(comments_df)*100:.1f}%)',
                                xy=(x, y),  # ç®­å¤´æŒ‡å‘ç§¯æåŒºåŸŸä¸­å¿ƒ
                                xytext=(1.2, 0.5),  # æ ‡ç­¾é è¿‘å›¾è¡¨
                                arrowprops=dict(arrowstyle='->', color='black', lw=1.5),
                                fontsize=11,
                                fontproperties=font_prop
                            )
                    
                    # ä¸­æ€§æ ‡ç­¾
                    ax.text(0, -1.2, f'ä¸­æ€§ ({sentiment_counts["ä¸­æ€§"]/len(comments_df)*100:.1f}%)', ha='center', fontsize=12, fontproperties=font_prop)
                    
                    ax.set_title('LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ', fontsize=14, fontproperties=font_prop)
                    ax.axis('equal')
                    st.pyplot(fig)
                    
                    # æ˜¾ç¤ºæ•°é‡
                    st.write('æƒ…æ„Ÿæ ‡ç­¾æ•°é‡ï¼š')
                    for label, count in sentiment_counts.items():
                        st.write(f'- {label}: {count} æ¡ ({count/len(comments_df)*100:.1f}%)')
                else:
                    st.write('æš‚æ— æƒ…æ„Ÿæ ‡ç­¾æ•°æ®')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰æƒ…æ„Ÿæ ‡ç­¾åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    with col2:
        # èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
        st.write('### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
        try:
            if 'ensemble_sentiment_score' in comments_df.columns:
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                mean_score = comments_df['ensemble_sentiment_score'].mean()
                median_score = comments_df['ensemble_sentiment_score'].median()
                std_score = comments_df['ensemble_sentiment_score'].std()
                
                # åˆ›å»ºç›´æ–¹å›¾
                fig, ax = plt.subplots(figsize=(8, 6))
                
                # ç»˜åˆ¶ç›´æ–¹å›¾
                sns.histplot(
                    comments_df['ensemble_sentiment_score'], 
                    bins=20, 
                    kde=True, 
                    ax=ax, 
                    color='#1f77b4', 
                    edgecolor='w'
                )
                
                # æ·»åŠ å‡å€¼å’Œä¸­ä½æ•°çº¿
                ax.axvline(mean_score, color='red', linestyle='--', label=f'å‡å€¼: {mean_score:.2f}')
                ax.axvline(median_score, color='green', linestyle='--', label=f'ä¸­ä½æ•°: {median_score:.2f}')
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾ï¼ˆæ˜¾å¼æŒ‡å®šå­—ä½“ï¼‰
                ax.set_title('èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ', fontsize=14, fontproperties=font_prop)
                ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
                ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12, fontproperties=font_prop)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹ï¼ˆæ˜¾å¼æŒ‡å®šå­—ä½“ï¼‰
                ax.legend(prop=font_prop)
                
                # è°ƒæ•´åˆ»åº¦å­—ä½“
                plt.xticks(fontproperties=font_prop)
                plt.yticks(fontproperties=font_prop)
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write('æƒ…æ„Ÿå¾—åˆ†ç»Ÿè®¡ï¼š')
                st.write(f'- å‡å€¼: {mean_score:.4f}')
                st.write(f'- ä¸­ä½æ•°: {median_score:.4f}')
                st.write(f'- æ ‡å‡†å·®: {std_score:.4f}')
                st.write(f'- æœ€å°å€¼: {comments_df["ensemble_sentiment_score"].min():.4f}')
                st.write(f'- æœ€å¤§å€¼: {comments_df["ensemble_sentiment_score"].max():.4f}')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰èåˆæƒ…æ„Ÿå¾—åˆ†åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    # æ˜¾ç¤ºå¹³å‡æƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡çš„å…³ç³»
    st.subheader('æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»åˆ†æ')
    
    try:
        if merged_df.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æã€‚')
        else:
            if len(merged_df) < 1:
                st.warning('æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œä»…æ˜¾ç¤ºåŸºæœ¬æ•°æ®æ¦‚è§ˆã€‚')
                st.write(f'æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}')
                st.write(f'æœ‰æ•ˆäº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ª')
                st.write(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
                st.write(f'å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
            else:
                # åˆ›å»ºæ•£ç‚¹å›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                
                if lag_days > 0:
                    scatter_x = merged_df['ensemble_mean_lag'] if 'ensemble_mean_lag' in merged_df.columns else merged_df['ensemble_mean']
                else:
                    scatter_x = merged_df['ensemble_mean']
                scatter_y = merged_df['next_day_return']
                
                # è¿‡æ»¤æ‰NaNå€¼
                valid_mask = scatter_x.notna() & scatter_y.notna()
                filtered_x = scatter_x[valid_mask]
                filtered_y = scatter_y[valid_mask]
                
                if len(filtered_x) < 1:
                    st.warning(f'æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼ˆ{len(filtered_x)}ä¸ªæ ·æœ¬ï¼‰ï¼Œä»…æ˜¾ç¤ºåŸºæœ¬å›¾è¡¨ã€‚')
                    ax.text(0.5, 0.5, f'ä»…æ‰¾åˆ°{len(filtered_x)}ä¸ªæœ‰æ•ˆæ ·æœ¬ç‚¹', transform=ax.transAxes, 
                            ha='center', va='center', fontsize=12, fontproperties=font_prop)
                    ax.set_title('æ•°æ®ä¸è¶³', fontsize=14, fontproperties=font_prop)
                else:
                    # æ ¹æ®æƒ…æ„Ÿå¾—åˆ†è®¾ç½®ä¸åŒé¢œè‰²
                    colors = ['red' if s < -0.1 else 'green' if s > 0.1 else 'blue' for s in filtered_x]
                    ax.scatter(filtered_x, filtered_y, c=colors, alpha=0.5)
                    ax.set_title(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³» (æ»å{lag_days}å¤©)', fontsize=14, fontproperties=font_prop)
                    ax.set_xlabel(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†(æ»å{lag_days}å¤©)' if lag_days > 0 else 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†', fontsize=12, fontproperties=font_prop)
                    ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡ (%)', fontsize=12, fontproperties=font_prop)
                    ax.grid(True, alpha=0.3)
                    
                    # è°ƒæ•´åˆ»åº¦å­—ä½“
                    plt.xticks(fontproperties=font_prop)
                    plt.yticks(fontproperties=font_prop)
                    
                    # å°è¯•ç®€å•çš„çº¿æ€§å›å½’
                    try:
                        if len(filtered_x) >= 2:
                            X_simple = filtered_x.values.reshape(-1, 1)
                            y_simple = filtered_y.values
                            model = LinearRegression()
                            model.fit(X_simple, y_simple)
                            r2_score = model.score(X_simple, y_simple)
                            
                            # ç»˜åˆ¶å›å½’çº¿
                            x_line = np.linspace(filtered_x.min(), filtered_x.max(), 100).reshape(-1, 1)
                            y_line = model.predict(x_line)
                            ax.plot(x_line, y_line, color='red', label=f'ç®€å•å›å½’çº¿ (RÂ²={r2_score:.3f})')
                            ax.legend(prop=font_prop)
                    except Exception as e:
                        pass
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # æ·»åŠ å›¾è¡¨è¯´æ˜
                st.write('ğŸ“Š å›¾è¡¨è¯´æ˜ï¼š')
                st.write('- ç»¿è‰²ç‚¹ï¼šç§¯ææƒ…æ„Ÿå¾—åˆ† (> 0.1)')
                st.write('- è“è‰²ç‚¹ï¼šä¸­æ€§æƒ…æ„Ÿå¾—åˆ† (Â± 0.1)')
                st.write('- çº¢è‰²ç‚¹ï¼šæ¶ˆææƒ…æ„Ÿå¾—åˆ† (< -0.1)')
                st.write('- çº¢è‰²çº¿ï¼šç®€å•å›å½’çº¿ (å¦‚é€‚ç”¨)')
                
                # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                st.subheader('åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯')
                st.write(f'æ€»äº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ª')
                st.write(f'æœ‰è¯„è®ºçš„äº¤æ˜“æ—¥æ•°é‡ï¼š{sum(merged_df["comment_count"] > 0)} ä¸ª')
                st.write(f'å¹³å‡æ¯æ—¥è¯„è®ºæ•°ï¼š{merged_df["comment_count"].mean():.2f} æ¡')
                st.write(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
                st.write(f'å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
                
                # è¯¦ç»†å›å½’åˆ†æ
                if len(merged_df) >= 3:
                    try:
                        if lag_days > 0:
                            required_cols = ['ensemble_mean_lag', 'comment_count_lag', 'ensemble_std_lag']
                            if not all(col in merged_df.columns for col in required_cols):
                                st.info(f'æ»å{lag_days}å¤©çš„æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨éæ»åæ•°æ®è¿›è¡Œåˆ†æã€‚')
                                X = merged_df[['ensemble_mean', 'comment_count', 'ensemble_std']]
                                current_lag = 0
                            else:
                                X = merged_df[required_cols]
                                current_lag = lag_days
                        else:
                            X = merged_df[['ensemble_mean', 'comment_count', 'ensemble_std']]
                            current_lag = 0
                        y = merged_df['next_day_return']
                        
                        valid_mask = X.notna().all(axis=1) & y.notna()
                        X_valid = X[valid_mask]
                        y_valid = y[valid_mask]
                        
                        if len(X_valid) >= 3:
                            st.subheader('å›å½’åˆ†æç»“æœ')
                            
                            try:
                                model = LinearRegression()
                                model.fit(X_valid, y_valid)
                                r2_score = model.score(X_valid, y_valid)
                                
                                st.write('**æ ‡å‡†çº¿æ€§å›å½’**')
                                st.write(f'RÂ²å€¼: {r2_score:.4f}')
                                st.write(f'æˆªè·: {model.intercept_:.4f}')
                                
                                if current_lag > 0:
                                    st.write(f'æ»åæƒ…æ„Ÿç³»æ•°: {model.coef_[0]:.4f}')
                                    st.write(f'æ»åè¯„è®ºæ•°ç³»æ•°: {model.coef_[1]:.4f}')
                                    st.write(f'æ»åæƒ…æ„Ÿæ³¢åŠ¨ç³»æ•°: {model.coef_[2]:.4f}')
                                else:
                                    st.write(f'æƒ…æ„Ÿç³»æ•°: {model.coef_[0]:.4f}')
                                    st.write(f'è¯„è®ºæ•°ç³»æ•°: {model.coef_[1]:.4f}')
                                    st.write(f'æƒ…æ„Ÿæ³¢åŠ¨ç³»æ•°: {model.coef_[2]:.4f}')
                            except Exception as e:
                                st.info(f'å¤šå˜é‡å›å½’å¤±è´¥: {str(e)}ï¼Œå°è¯•å•å˜é‡å›å½’ã€‚')
                                
                                X_simple = X_valid[[X_valid.columns[0]]]
                                model = LinearRegression()
                                model.fit(X_simple, y_valid)
                                r2_score = model.score(X_simple, y_valid)
                                
                                st.write('**å•å˜é‡çº¿æ€§å›å½’**')
                                st.write(f'RÂ²å€¼: {r2_score:.4f}')
                                st.write(f'æˆªè·: {model.intercept_:.4f}')
                                st.write(f'{X_simple.columns[0]}ç³»æ•°: {model.coef_[0]:.4f}')
                            
                            st.info(f'ğŸ’¡ å›å½’åˆ†æè§£é‡Šï¼š')
                            st.write(f'- RÂ²å€¼è¶Šæ¥è¿‘1ï¼Œè¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆæ•ˆæœè¶Šå¥½')
                            st.write(f'- æƒ…æ„Ÿç³»æ•°ä¸ºæ­£ï¼Œè¡¨ç¤ºæƒ…æ„Ÿè¶Šç§¯æï¼Œæ¬¡æ—¥æ”¶ç›Šç‡å¯èƒ½è¶Šé«˜')
                    except Exception as e:
                        st.info(f'è¯¦ç»†å›å½’åˆ†æä¸å¯ç”¨: {str(e)}')
    except Exception as e:
        st.error(f'è¿›è¡Œæƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»åˆ†ææ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        if not merged_df.empty:
            st.write('ğŸ“Š åŸºæœ¬æ•°æ®æ¦‚è§ˆï¼š')
            st.write(f'æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}')
            st.write(f'æœ‰æ•ˆäº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ª')
            st.write(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
            st.write(f'å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
        else:
            st.write('æ— æ³•è·å–æœ‰æ•ˆæ•°æ®è¿›è¡Œåˆ†æã€‚')
    
    # æ˜¾ç¤ºè¯„è®ºç¤ºä¾‹
    st.subheader('è¯„è®ºç¤ºä¾‹')
    selected_sentiment = st.selectbox('é€‰æ‹©æƒ…æ„Ÿç±»å‹', ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ'])
    sentiment_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == selected_sentiment]
    if len(sentiment_comments) > 0:
        st.dataframe(sentiment_comments[['post_publish_time', 'combined_text']].sample(min(10, len(sentiment_comments))))
    else:
        st.write(f'æ²¡æœ‰æ‰¾åˆ°{selected_sentiment}æƒ…æ„Ÿç±»å‹çš„è¯„è®ºç¤ºä¾‹ã€‚')
    
    # å‚æ•°å½±å“åˆ†æ
    st.subheader('å½“å‰å‚æ•°å½±å“åˆ†æ')
        
    st.write(f'ğŸ“ æ–‡æœ¬é•¿åº¦é™åˆ¶: {text_length} å­—ç¬¦ï¼ˆè¿‡æ»¤æ‰ {len(comments_df) - len(filtered_comments)} æ¡é•¿è¯„è®ºï¼‰')
    st.write(f'ğŸ“Š ç§»åŠ¨å¹³å‡çª—å£: {window_size} å¤©ï¼ˆå¹³æ»‘æƒ…æ„Ÿå’Œæ”¶ç›Šç‡æ•°æ®ï¼‰')
    st.write(f'â±ï¸ æƒ…æ„Ÿæ»åå¤©æ•°: {lag_days} å¤©ï¼ˆåˆ†ææƒ…æ„Ÿå¯¹æœªæ¥ {lag_days} å¤©æ”¶ç›Šç‡çš„å½±å“ï¼‰')
    st.write(f'ğŸ² LLMæ¸©åº¦å‚æ•°: {temperature}ï¼ˆå½±å“æ¨¡å‹ç”Ÿæˆçš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜ç”Ÿæˆå†…å®¹è¶Šå¤šæ ·ï¼‰')
    
    st.info('ğŸ’¡ æç¤ºï¼šè°ƒæ•´ä»»ä½•å‚æ•°åï¼Œåº”ç”¨å°†è‡ªåŠ¨é‡æ–°è¿è¡Œå¹¶æ›´æ–°æ‰€æœ‰åˆ†æç»“æœã€‚')

except Exception as e:
    st.error(f'å‘ç”Ÿé”™è¯¯: {e}')
    st.write('è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚')
