import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, RANSACRegressor
import warnings
import os
import requests
from collections import Counter
import re
import matplotlib.font_manager as fm

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º - ä¿®å¤äº‘ç«¯ä¸­æ–‡ä¹±ç é—®é¢˜
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œè§£å†³äº‘ç«¯ç¯å¢ƒä¸­æ–‡æ˜¾ç¤ºé—®é¢˜"""
    try:
        # å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
    except:
        # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False

setup_chinese_font()
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½æƒ…æ„Ÿè¯å…¸ - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def load_sentiment_dictionaries():
    """
    åŠ è½½ç”¨æˆ·æä¾›çš„æƒ…æ„Ÿè¯å…¸
    ç§¯æè¯å…¸ï¼šzhang_unformal_pos (1).txt
    æ¶ˆæè¯å…¸ï¼šzhang_unformal_neg (1).txt
    """
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ„å»ºè¯å…¸æ–‡ä»¶è·¯å¾„
    pos_dict_path = os.path.join(script_dir, 'zhang_unformal_pos (1).txt')
    neg_dict_path = os.path.join(script_dir, 'zhang_unformal_neg (1).txt')
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(pos_dict_path) or not os.path.exists(neg_dict_path):
        st.error(f"æƒ…æ„Ÿè¯å…¸æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- {pos_dict_path}\n- {neg_dict_path}")
        st.stop()
    
    # åŠ è½½ç§¯æè¯å…¸
    with open(pos_dict_path, 'r', encoding='utf-8') as f:
        positive_words = [line.strip() for line in f if line.strip()]
    
    # åŠ è½½æ¶ˆæè¯å…¸
    with open(neg_dict_path, 'r', encoding='utf-8') as f:
        negative_words = [line.strip() for line in f if line.strip()]
    
    return positive_words, negative_words

# å®ç°åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
def lexicon_based_sentiment_analysis(text, pos_words, neg_words):
    """
    åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    text: è¯„è®ºæ–‡æœ¬
    pos_words: ç§¯æè¯è¯­åˆ—è¡¨
    neg_words: æ¶ˆæè¯è¯­åˆ—è¡¨
    è¿”å›ï¼š
    - sentiment_label: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰
    - sentiment_score: æƒ…æ„Ÿå¾—åˆ†ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
    """
    if pd.isna(text) or text.strip() == '':
        return 'ä¸­æ€§', 0.0
    
    # è®¡ç®—ç§¯æè¯è¯­å’Œæ¶ˆæè¯è¯­çš„å‡ºç°æ¬¡æ•°
    pos_count = sum(1 for word in pos_words if word in text)
    neg_count = sum(1 for word in neg_words if word in text)
    
    # è®¡ç®—æƒ…æ„Ÿå¾—åˆ†
    total = pos_count + neg_count + 1  # åŠ 1é¿å…é™¤ä»¥0
    sentiment_score = (pos_count - neg_count) / total
    
    # ç¡®å®šæƒ…æ„Ÿæ ‡ç­¾
    if sentiment_score > 0.1:
        sentiment_label = 'ç§¯æ'
    elif sentiment_score < -0.1:
        sentiment_label = 'æ¶ˆæ'
    else:
        sentiment_label = 'ä¸­æ€§'
    
    return sentiment_label, sentiment_score

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title('ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ')

# åŠ è½½æ•°æ® - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def load_data():
    # åŠ è½½è¯„è®ºå’Œæƒ…æ„Ÿåˆ†ææ•°æ®
    # ä¼˜å…ˆä½¿ç”¨æ›´æ–°åçš„æƒ…æ„Ÿåˆ†æç»“æœæ–‡ä»¶
    updated_file = "300059_sentiment_analysis_updated.csv"
    original_file = "300059_sentiment_analysis.csv"
    
    try:
        if os.path.exists(updated_file):
            comments_df = pd.read_csv(updated_file)
            st.success(f"å·²åŠ è½½æ”¹è¿›çš„æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
        elif os.path.exists(original_file):
            comments_df = pd.read_csv(original_file)
            st.info(f"å·²åŠ è½½åŸå§‹æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
        else:
            st.error("æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- 300059_sentiment_analysis_updated.csv\n- 300059_sentiment_analysis.csv")
            st.stop()
        
        comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'])
        
        # åŠ è½½ä»·æ ¼æ•°æ®
        price_file = "300059_price_data.csv"
        if os.path.exists(price_file):
            price_df = pd.read_csv(price_file)
            price_df['trade_date'] = pd.to_datetime(price_df['trade_date'])
        else:
            st.error("æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- 300059_price_data.csv")
            st.stop()
        
        return comments_df, price_df
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        st.stop()

# å¤„ç†æ•°æ® - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def process_data(comments_df, price_df, text_length_limit=500, window_size=30, lag_days=0):
    # å¤„ç†combined_textå­—æ®µä¸ºç©ºçš„æƒ…å†µ
    filtered_comments = comments_df.copy()
    
    # è°ƒæ•´æ–‡æœ¬å­—æ®µä¼˜å…ˆçº§ï¼šä¼˜å…ˆä½¿ç”¨post_titleï¼Œå†ä½¿ç”¨combined_textå’Œprocessed_content
    if 'post_title' in filtered_comments.columns:
        filtered_comments['combined_text'] = filtered_comments['post_title']
    elif 'combined_text' in filtered_comments.columns:
        filtered_comments['combined_text'] = filtered_comments['combined_text']
    else:
        st.error("æ•°æ®ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æœ¬åˆ—ï¼ˆpost_titleæˆ–combined_textï¼‰")
        return pd.DataFrame(), pd.DataFrame()
    
    # è¿‡æ»¤æ— æ•ˆè¯„è®ºå†…å®¹
    invalid_pattern = r'(å›¾ç‰‡å›¾ç‰‡|è½¬å‘è½¬å‘|^[!ï¼]{5,}$|^[?ï¼Ÿ]{5,}$|^\.{5,}$|^\s*$)'
    filtered_comments = filtered_comments[~filtered_comments['combined_text'].str.contains(invalid_pattern, na=False, regex=True)]
    
    # åŠ è½½æƒ…æ„Ÿè¯å…¸
    try:
        positive_words, negative_words = load_sentiment_dictionaries()
    except Exception as e:
        st.error(f"åŠ è½½æƒ…æ„Ÿè¯å…¸å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame(), pd.DataFrame()
    
    # åº”ç”¨åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    sentiment_results = filtered_comments['combined_text'].apply(
        lambda x: lexicon_based_sentiment_analysis(x, positive_words, negative_words)
    )
    
    # å°†ç»“æœæ‹†åˆ†ä¸ºæƒ…æ„Ÿæ ‡ç­¾å’Œæƒ…æ„Ÿå¾—åˆ†
    filtered_comments['llm_sentiment_label'] = sentiment_results.str[0]
    filtered_comments['llm_sentiment_score'] = sentiment_results.str[1]
    filtered_comments['ensemble_sentiment_score'] = sentiment_results.str[1]
    filtered_comments['lexicon_sentiment'] = sentiment_results.str[1]
    
    # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
    filtered_comments['text_length'] = filtered_comments['combined_text'].str.len()
    filtered_comments = filtered_comments[(filtered_comments['text_length'] >= 1) & (filtered_comments['text_length'] <= text_length_limit)]
    
    # æŒ‰æ—¥æœŸèšåˆæƒ…æ„Ÿæ•°æ®
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg({
        'ensemble_sentiment_score': ['mean', 'median', 'std', 'count'],
        'llm_sentiment_score': 'mean',
        'lexicon_sentiment': 'mean'
    }).reset_index()
    
    # é‡å‘½ååˆ—
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_median', 'ensemble_std', 'comment_count', 'llm_mean', 'lexicon_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # åˆå¹¶ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨å·¦è¿æ¥ï¼Œä¿ç•™æ‰€æœ‰ä»·æ ¼æ—¥æœŸï¼‰
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    
    # å¤„ç†æ²¡æœ‰è¯„è®ºçš„æ—¥æœŸï¼ˆå¡«å……NaNå€¼ï¼‰
    merged_df['comment_count'] = merged_df['comment_count'].fillna(0)
    merged_df['ensemble_mean'] = merged_df['ensemble_mean'].fillna(0)
    merged_df['ensemble_median'] = merged_df['ensemble_median'].fillna(0)
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    merged_df['llm_mean'] = merged_df['llm_mean'].fillna(0)
    merged_df['lexicon_mean'] = merged_df['lexicon_mean'].fillna(0)
    
    # ç¡®ä¿stdåˆ—ä¸ä¸ºNaN
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    
    # æ·»åŠ æ»åæƒ…æ„Ÿæ•°æ®
    if lag_days > 0:
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days)
        merged_df['comment_count_lag'] = merged_df['comment_count'].shift(lag_days)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std'].shift(lag_days)
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean_lag'].fillna(0)
        merged_df['comment_count_lag'] = merged_df['comment_count_lag'].fillna(0)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std_lag'].fillna(0)
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡
    if window_size > 1:
        merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size).mean()
        merged_df['next_day_return_rolling'] = merged_df['next_day_return'].rolling(window=window_size).mean()
    
    return merged_df, filtered_comments

# ä¾§è¾¹æ ï¼šå‚æ•°è°ƒæ•´
st.sidebar.subheader('å‚æ•°è°ƒæ•´')

# ä½¿ç”¨session_stateç®¡ç†å‚æ•°çŠ¶æ€
if 'text_length' not in st.session_state:
    st.session_state.text_length = 500
if 'window_size' not in st.session_state:
    st.session_state.window_size = 30
if 'lag_days' not in st.session_state:
    st.session_state.lag_days = 0

# é‡ç½®æŒ‰é’®
if st.sidebar.button('ğŸ”„ é‡ç½®æ‰€æœ‰å‚æ•°'):
    st.session_state.text_length = 500
    st.session_state.window_size = 30
    st.session_state.lag_days = 0
    st.experimental_rerun()

text_length = st.sidebar.slider('æ–‡æœ¬é•¿åº¦é™åˆ¶', 50, 1000, st.session_state.text_length, step=50, key='length_slider')
window_size = st.sidebar.slider('ç§»åŠ¨å¹³å‡çª—å£å¤§å°(å¤©)', 1, 90, st.session_state.window_size, step=5, key='window_slider')
lag_days = st.sidebar.slider('æƒ…æ„Ÿæ»åå¤©æ•°', 0, 10, st.session_state.lag_days, step=1, key='lag_slider')

# æ›´æ–°session_state
st.session_state.text_length = text_length
st.session_state.window_size = window_size
st.session_state.lag_days = lag_days

# åŠ è½½å’Œå¤„ç†æ•°æ®
try:
    comments_df, price_df = load_data()
    merged_df, filtered_comments = process_data(comments_df, price_df, text_length, window_size, lag_days)
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    st.subheader('æ•°æ®è´¨é‡æ£€æŸ¥')
    
    # æ£€æŸ¥è¯„è®ºæ•°é‡
    total_comments = len(comments_df)
    filtered_count = len(filtered_comments)
    filtered_out_count = total_comments - filtered_count
    zero_sentiment = (comments_df['ensemble_sentiment_score'] == 0).sum()
    
    st.write(f'ğŸ“Š æ•°æ®æ¦‚è§ˆï¼š')
    st.write(f'- å…±æ”¶é›†åˆ° {total_comments} æ¡è¯„è®º')
    st.write(f'- ç»è¿‡è¿‡æ»¤åä¿ç•™ï¼š{filtered_count} æ¡æœ‰æ•ˆè¯„è®º')
    st.write(f'- è¿‡æ»¤æ‰çš„è¯„è®ºï¼š{filtered_out_count} æ¡ï¼ˆå†…å®¹æ— æ•ˆæˆ–ä¸ç¬¦åˆé•¿åº¦è¦æ±‚ï¼‰')
    st.write(f'- ä¸­æ€§æƒ…æ„Ÿè¯„è®ºï¼ˆåˆ†æ•°ä¸º0ï¼‰ï¼š{zero_sentiment} æ¡')
    st.write(f'- ä¿ç•™çš„äº¤æ˜“æ—¥æ•°æ®ï¼š{len(merged_df)} ä¸ª')
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    if filtered_count < total_comments * 0.5:
        st.warning(f'æ³¨æ„ï¼šæœ‰ {filtered_out_count} æ¡è¯„è®ºè¢«è¿‡æ»¤ï¼Œä¿ç•™çš„æœ‰æ•ˆæ ·æœ¬è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    if zero_sentiment > total_comments * 0.8:
        st.warning(f'æ³¨æ„ï¼š{zero_sentiment/total_comments:.1%} çš„è¯„è®ºæƒ…æ„Ÿåˆ†æ•°ä¸º0ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    # æ£€æŸ¥æ—¥æœŸèŒƒå›´
    if not merged_df.empty:
        date_range = f'{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}'
        st.write(f'- æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{date_range}')
    
    # æ˜¾ç¤ºè¯„è®ºæ•°é‡éšæ—¶é—´çš„å˜åŒ–
    st.subheader('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–')
    
    try:
        # æŒ‰æ—¥æœŸåˆ†ç»„å¹¶è®¡ç®—è¯„è®ºæ•°é‡
        daily_comments = comments_df.groupby(comments_df['post_publish_time'].dt.date)['post_id'].count()
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(daily_comments) > 0:
            # ç»˜åˆ¶æŠ˜çº¿å›¾
            daily_comments.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=5, color='#1f77b4')
            
            # æ·»åŠ æ¯æ—¥è¯„è®ºæ•°é‡æ ‡ç­¾
            for x, y in zip(daily_comments.index, daily_comments.values):
                ax.text(x, y + 0.5, str(y), ha='center', va='bottom', fontsize=9)
            
            # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡å˜åŒ–è¶‹åŠ¿', fontsize=14)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
            
            # è°ƒæ•´Yè½´èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰ç‚¹éƒ½èƒ½æ˜¾ç¤º
            ax.set_ylim(0, daily_comments.max() * 1.1)
            
            # æ·»åŠ ç½‘æ ¼çº¿
            ax.grid(True, alpha=0.3)
            
            # è°ƒæ•´æ—¥æœŸæ ‡ç­¾
            plt.xticks(rotation=45, fontsize=10)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_daily = daily_comments.mean()
            max_daily = daily_comments.max()
            min_daily = daily_comments.min()
            
            # åœ¨å›¾è¡¨ä¸­æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            stats_text = f'å¹³å‡æ—¥è¯„è®ºæ•°: {avg_daily:.1f}\næœ€é«˜æ—¥è¯„è®ºæ•°: {max_daily}\næœ€ä½æ—¥è¯„è®ºæ•°: {min_daily}'
            ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8), fontsize=10)
        else:
            ax.set_title('æš‚æ— è¯„è®ºæ•°æ®', fontsize=14)
            ax.text(0.5, 0.5, 'æ²¡æœ‰è¶³å¤Ÿçš„è¯„è®ºæ•°æ®æ¥ç»˜åˆ¶è¶‹åŠ¿å›¾', transform=ax.transAxes, ha='center', va='center', fontsize=12)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.pyplot(fig)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if len(daily_comments) > 0:
            st.write(f'ğŸ“Š è¯„è®ºæ•°é‡ç»Ÿè®¡ï¼š')
            st.write(f'- è¯„è®ºæ—¥æœŸèŒƒå›´ï¼š{daily_comments.index.min()} è‡³ {daily_comments.index.max()}')
            st.write(f'- æœ‰è¯„è®ºçš„å¤©æ•°ï¼š{len(daily_comments)} å¤©')
            st.write(f'- å¹³å‡æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.mean():.1f} æ¡')
            st.write(f'- æœ€é«˜æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.max()} æ¡')
            st.write(f'- æœ€ä½æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.min()} æ¡')
        else:
            st.warning('æ²¡æœ‰è¯„è®ºæ•°æ®å¯æ˜¾ç¤ºã€‚')
    except Exception as e:
        st.error(f'ç»˜åˆ¶è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æç»“æœ
    st.subheader('æƒ…æ„Ÿåˆ†æç»“æœ')
    
    col1, col2 = st.columns(2)
    
    with col1:
        # LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ
        st.write('### æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ')
        try:
            # æ£€æŸ¥æƒ…æ„Ÿæ ‡ç­¾åˆ—æ˜¯å¦å­˜åœ¨ä¸”éç©º
            if 'llm_sentiment_label' in comments_df.columns:
                sentiment_counts = comments_df['llm_sentiment_label'].value_counts()
                
                if len(sentiment_counts) > 0:
                    # åˆ›å»ºé¥¼å›¾
                    fig, ax = plt.subplots(figsize=(8, 6))
                    
                    # è®¾ç½®é¥¼å›¾é¢œè‰²
                    colors = ['#4caf50' if label == 'ç§¯æ' else '#ff9800' if label == 'ä¸­æ€§' else '#f44336' for label in sentiment_counts.index]
                    
                    # ç»˜åˆ¶é¥¼å›¾
                    patches, texts, autotexts = ax.pie(
                        sentiment_counts.values, 
                        labels=sentiment_counts.index, 
                        autopct='%1.1f%%', 
                        startangle=90, 
                        colors=colors, 
                        wedgeprops={'edgecolor': 'white', 'linewidth': 1}, 
                        textprops={'fontsize': 12}
                    )
                    
                    # è®¾ç½®ç™¾åˆ†æ¯”æ ‡ç­¾é¢œè‰²å’Œå¤§å°
                    for autotext in autotexts:
                        autotext.set_color('white')
                        autotext.set_fontsize(11)
                    
                    # è®¾ç½®æ ‡é¢˜
                    ax.set_title('LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ', fontsize=14)
                    
                    # ç¡®ä¿é¥¼å›¾æ˜¯åœ†å½¢
                    ax.axis('equal')
                    
                    # æ˜¾ç¤ºå›¾è¡¨
                    st.pyplot(fig)
                    
                    # æ˜¾ç¤ºå…·ä½“æ•°é‡
                    st.write('æƒ…æ„Ÿæ ‡ç­¾æ•°é‡ï¼š')
                    for label, count in sentiment_counts.items():
                        st.write(f'- {label}: {count} æ¡ ({count/len(comments_df)*100:.1f}%)')
                else:
                    st.write('æš‚æ— æƒ…æ„Ÿæ ‡ç­¾æ•°æ®')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰æƒ…æ„Ÿæ ‡ç­¾åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    with col2:
        # èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
        st.write('### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
        try:
            # æ£€æŸ¥æƒ…æ„Ÿå¾—åˆ†åˆ—æ˜¯å¦å­˜åœ¨
            if 'ensemble_sentiment_score' in comments_df.columns:
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                mean_score = comments_df['ensemble_sentiment_score'].mean()
                median_score = comments_df['ensemble_sentiment_score'].median()
                std_score = comments_df['ensemble_sentiment_score'].std()
                
                # åˆ›å»ºç›´æ–¹å›¾
                fig, ax = plt.subplots(figsize=(8, 6))
                
                # ç»˜åˆ¶ç›´æ–¹å›¾
                sns.histplot(
                    comments_df['ensemble_sentiment_score'], 
                    bins=20, 
                    kde=True, 
                    ax=ax, 
                    color='#1f77b4', 
                    edgecolor='w'
                )
                
                # æ·»åŠ å‡å€¼å’Œä¸­ä½æ•°çº¿
                ax.axvline(mean_score, color='red', linestyle='--', label=f'å‡å€¼: {mean_score:.2f}')
                ax.axvline(median_score, color='green', linestyle='--', label=f'ä¸­ä½æ•°: {median_score:.2f}')
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title('èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ', fontsize=14)
                ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
                ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹
                ax.legend()
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write('æƒ…æ„Ÿå¾—åˆ†ç»Ÿè®¡ï¼š')
                st.write(f'- å‡å€¼: {mean_score:.4f}')
                st.write(f'- ä¸­ä½æ•°: {median_score:.4f}')
                st.write(f'- æ ‡å‡†å·®: {std_score:.4f}')
                st.write(f'- æœ€å°å€¼: {comments_df["ensemble_sentiment_score"].min():.4f}')
                st.write(f'- æœ€å¤§å€¼: {comments_df["ensemble_sentiment_score"].max():.4f}')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰èåˆæƒ…æ„Ÿå¾—åˆ†åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    # æ˜¾ç¤ºå¹³å‡æƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡çš„å…³ç³»
    st.subheader('æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»åˆ†æ')
    
    try:
        if merged_df.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æã€‚')
        else:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿè¿›è¡Œåˆ†æ
            if len(merged_df) < 1:
                st.warning('æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œä»…æ˜¾ç¤ºåŸºæœ¬æ•°æ®æ¦‚è§ˆã€‚')
                
                # æ˜¾ç¤ºåŸºæœ¬æ•°æ®ä¿¡æ¯
                st.write(f'æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}')
                st.write(f'æœ‰æ•ˆäº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ª')
                st.write(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
                st.write(f'å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
            else:
                # å³ä½¿æ•°æ®æœ‰é™ï¼Œä¹Ÿå°è¯•æ˜¾ç¤ºåŸºæœ¬æ•£ç‚¹å›¾
                fig, ax = plt.subplots(figsize=(12, 8))
                
                # é€‰æ‹©è¦æ˜¾ç¤ºçš„æ•°æ®
                if lag_days > 0 and 'ensemble_mean_lag' in merged_df.columns:
                    x_data = merged_df['ensemble_mean_lag']
                    x_label = f'æƒ…æ„Ÿå¾—åˆ†(æ»å{lag_days}å¤©)'
                else:
                    x_data = merged_df['ensemble_mean']
                    x_label = 'å½“æ—¥æƒ…æ„Ÿå¾—åˆ†'
                
                y_data = merged_df['next_day_return']
                
                # ç»˜åˆ¶æ•£ç‚¹å›¾
                scatter = ax.scatter(x_data, y_data, alpha=0.7, s=60, c='blue', edgecolors='w', linewidth=0.5)
                
                # æ·»åŠ è¶‹åŠ¿çº¿
                if len(x_data.dropna()) > 1 and len(y_data.dropna()) > 1:
                    try:
                        # ä½¿ç”¨çº¿æ€§å›å½’æ‹Ÿåˆè¶‹åŠ¿çº¿
                        x_valid = x_data.dropna()
                        y_valid = y_data.dropna()
                        
                        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
                        min_len = min(len(x_valid), len(y_valid))
                        x_valid = x_valid.iloc[:min_len]
                        y_valid = y_valid.iloc[:min_len]
                        
                        if len(x_valid) > 1:
                            # ä½¿ç”¨RANSACå›å½’å™¨ï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’
                            model = RANSACRegressor()
                            model.fit(x_valid.values.reshape(-1, 1), y_valid)
                            x_range = np.linspace(x_valid.min(), x_valid.max(), 100)
                            y_pred = model.predict(x_range.reshape(-1, 1))
                            ax.plot(x_range, y_pred, 'r-', linewidth=2, label='è¶‹åŠ¿çº¿')
                            
                            # è®¡ç®—ç›¸å…³ç³»æ•°
                            corr_coef = np.corrcoef(x_valid, y_valid)[0, 1]
                            ax.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr_coef:.3f}', transform=ax.transAxes, 
                                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                    except Exception as e:
                        # å¦‚æœè¶‹åŠ¿çº¿æ‹Ÿåˆå¤±è´¥ï¼Œåªæ˜¾ç¤ºæ•£ç‚¹å›¾
                        pass
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title(f'{x_label}ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³»', fontsize=14)
                ax.set_xlabel(x_label, fontsize=12)
                ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡(%)', fontsize=12)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹
                ax.legend()
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write(f'ğŸ“Š {x_label}ä¸æ¬¡æ—¥æ”¶ç›Šç‡ç»Ÿè®¡ï¼š')
                st.write(f'- æ•°æ®ç‚¹æ•°é‡ï¼š{len(x_data.dropna())} ä¸ª')
                st.write(f'- å¹³å‡{x_label}ï¼š{x_data.mean():.4f}')
                st.write(f'- å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{y_data.mean():.4f}%')
                st.write(f'- {x_label}æ ‡å‡†å·®ï¼š{x_data.std():.4f}')
                st.write(f'- æ¬¡æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼š{y_data.std():.4f}%')
                
                # è®¡ç®—ç›¸å…³æ€§
                if len(x_data.dropna()) > 1 and len(y_data.dropna()) > 1:
                    x_valid = x_data.dropna()
                    y_valid = y_data.dropna()
                    
                    # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
                    min_len = min(len(x_valid), len(y_valid))
                    x_valid = x_valid.iloc[:min_len]
                    y_valid = y_valid.iloc[:min_len]
                    
                    if len(x_valid) > 1:
                        corr_coef = np.corrcoef(x_valid, y_valid)[0, 1]
                        st.write(f'- ç›¸å…³ç³»æ•°ï¼š{corr_coef:.4f}')
                        
                        # è§£é‡Šç›¸å…³æ€§
                        if abs(corr_coef) < 0.1:
                            st.write('- ç›¸å…³æ€§è§£é‡Šï¼šæƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å‡ ä¹æ²¡æœ‰çº¿æ€§ç›¸å…³æ€§')
                        elif abs(corr_coef) < 0.3:
                            st.write('- ç›¸å…³æ€§è§£é‡Šï¼šæƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å­˜åœ¨å¼±ç›¸å…³æ€§')
                        elif abs(corr_coef) < 0.5:
                            st.write('- ç›¸å…³æ€§è§£é‡Šï¼šæƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å­˜åœ¨ä¸­ç­‰ç›¸å…³æ€§')
                        else:
                            st.write('- ç›¸å…³æ€§è§£é‡Šï¼šæƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å­˜åœ¨å¼ºç›¸å…³æ€§')
                        
                        if corr_coef < 0:
                            st.write('- ç›¸å…³æ€§æ–¹å‘ï¼šè´Ÿç›¸å…³ï¼ˆæƒ…æ„Ÿå¾—åˆ†è¶Šé«˜ï¼Œæ¬¡æ—¥æ”¶ç›Šç‡è¶Šä½ï¼‰')
                        else:
                            st.write('- ç›¸å…³æ€§æ–¹å‘ï¼šæ­£ç›¸å…³ï¼ˆæƒ…æ„Ÿå¾—åˆ†è¶Šé«˜ï¼Œæ¬¡æ—¥æ”¶ç›Šç‡è¶Šé«˜ï¼‰')
    except Exception as e:
        st.error(f'ç»˜åˆ¶æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºæ—¶é—´åºåˆ—åˆ†æ
    st.subheader('æ—¶é—´åºåˆ—åˆ†æ')
    
    try:
        if merged_df.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æã€‚')
        else:
            # åˆ›å»ºæ—¶é—´åºåˆ—å›¾è¡¨
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
            
            # ç»˜åˆ¶æƒ…æ„Ÿå¾—åˆ†æ—¶é—´åºåˆ—
            ax1.plot(merged_df['trade_date'], merged_df['ensemble_mean'], 'b-', linewidth=2, label='æƒ…æ„Ÿå¾—åˆ†')
            if window_size > 1 and 'ensemble_mean_rolling' in merged_df.columns:
                ax1.plot(merged_df['trade_date'], merged_df['ensemble_mean_rolling'], 'r--', linewidth=2, label=f'{window_size}æ—¥ç§»åŠ¨å¹³å‡')
            ax1.set_title('æƒ…æ„Ÿå¾—åˆ†æ—¶é—´åºåˆ—', fontsize=14)
            ax1.set_ylabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # ç»˜åˆ¶æ”¶ç›Šç‡æ—¶é—´åºåˆ—
            ax2.plot(merged_df['trade_date'], merged_df['next_day_return'], 'g-', linewidth=2, label='æ¬¡æ—¥æ”¶ç›Šç‡')
            if window_size > 1 and 'next_day_return_rolling' in merged_df.columns:
                ax2.plot(merged_df['trade_date'], merged_df['next_day_return_rolling'], 'r--', linewidth=2, label=f'{window_size}æ—¥ç§»åŠ¨å¹³å‡')
            ax2.set_title('æ¬¡æ—¥æ”¶ç›Šç‡æ—¶é—´åºåˆ—', fontsize=14)
            ax2.set_xlabel('æ—¥æœŸ', fontsize=12)
            ax2.set_ylabel('æ”¶ç›Šç‡(%)', fontsize=12)
            ax2.grid(True, alpha=0.3)
            ax2.legend()
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
            
            # æ˜¾ç¤ºå›¾è¡¨
            st.pyplot(fig)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.write('ğŸ“Š æ—¶é—´åºåˆ—ç»Ÿè®¡ï¼š')
            st.write(f'- æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}')
            st.write(f'- å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
            st.write(f'- æƒ…æ„Ÿå¾—åˆ†æ ‡å‡†å·®ï¼š{merged_df["ensemble_mean"].std():.4f}')
            st.write(f'- å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
            st.write(f'- æ¬¡æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼š{merged_df["next_day_return"].std():.4f}%')
            
            # è®¡ç®—æƒ…æ„Ÿå¾—åˆ†å’Œæ”¶ç›Šç‡çš„ç›¸å…³æ€§
            if len(merged_df['ensemble_mean'].dropna()) > 1 and len(merged_df['next_day_return'].dropna()) > 1:
                corr_coef = np.corrcoef(merged_df['ensemble_mean'].dropna(), merged_df['next_day_return'].dropna())[0, 1]
                st.write(f'- æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡ç›¸å…³ç³»æ•°ï¼š{corr_coef:.4f}')
    except Exception as e:
        st.error(f'ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºå›å½’åˆ†æç»“æœ
    st.subheader('å›å½’åˆ†æç»“æœ')
    
    try:
        if merged_df.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æã€‚')
        else:
            # å‡†å¤‡å›å½’æ•°æ®
            if lag_days > 0 and 'ensemble_mean_lag' in merged_df.columns:
                X = merged_df[['ensemble_mean_lag', 'comment_count_lag']].fillna(0)
                feature_names = [f'æƒ…æ„Ÿå¾—åˆ†(æ»å{lag_days}å¤©)', f'è¯„è®ºæ•°é‡(æ»å{lag_days}å¤©)']
            else:
                X = merged_df[['ensemble_mean', 'comment_count']].fillna(0)
                feature_names = ['æƒ…æ„Ÿå¾—åˆ†', 'è¯„è®ºæ•°é‡']
            
            y = merged_df['next_day_return'].fillna(0)
            
            # ç¡®ä¿æ•°æ®ä¸ä¸ºç©º
            if len(X.dropna()) == 0 or len(y.dropna()) == 0:
                st.warning('å›å½’åˆ†ææ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚')
            else:
                # ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹
                model = LinearRegression()
                model.fit(X, y)
                
                # è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡
                r2 = model.score(X, y)
                y_pred = model.predict(X)
                mse = np.mean((y - y_pred) ** 2)
                
                # æ˜¾ç¤ºæ¨¡å‹ç»“æœ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write('### æ¨¡å‹è¯„ä¼°æŒ‡æ ‡')
                    st.write(f'- RÂ²å¾—åˆ†ï¼š{r2:.4f}')
                    st.write(f'- å‡æ–¹è¯¯å·®(MSE)ï¼š{mse:.4f}')
                    
                    # è§£é‡ŠRÂ²å¾—åˆ†
                    if r2 < 0.1:
                        st.write('- æ¨¡å‹è§£é‡ŠåŠ›ï¼šæ¨¡å‹è§£é‡ŠåŠ›å¾ˆå¼±ï¼Œæƒ…æ„ŸæŒ‡æ ‡å¯¹æ”¶ç›Šç‡çš„è§£é‡Šèƒ½åŠ›æœ‰é™')
                    elif r2 < 0.3:
                        st.write('- æ¨¡å‹è§£é‡ŠåŠ›ï¼šæ¨¡å‹è§£é‡ŠåŠ›è¾ƒå¼±ï¼Œæƒ…æ„ŸæŒ‡æ ‡å¯¹æ”¶ç›Šç‡æœ‰ä¸€å®šå½±å“')
                    elif r2 < 0.5:
                        st.write('- æ¨¡å‹è§£é‡ŠåŠ›ï¼šæ¨¡å‹è§£é‡ŠåŠ›ä¸­ç­‰ï¼Œæƒ…æ„ŸæŒ‡æ ‡å¯¹æ”¶ç›Šç‡æœ‰æ˜¾è‘—å½±å“')
                    else:
                        st.write('- æ¨¡å‹è§£é‡ŠåŠ›ï¼šæ¨¡å‹è§£é‡ŠåŠ›è¾ƒå¼ºï¼Œæƒ…æ„ŸæŒ‡æ ‡å¯¹æ”¶ç›Šç‡æœ‰å¾ˆå¤§å½±å“')
                
                with col2:
                    st.write('### å›å½’ç³»æ•°')
                    for i, (name, coef) in enumerate(zip(feature_names, model.coef_)):
                        st.write(f'- {name}ï¼š{coef:.6f}')
                    st.write(f'- æˆªè·ï¼š{model.intercept_:.6f}')
                
                # åˆ›å»ºå›å½’ç³»æ•°å¯è§†åŒ–
                fig, ax = plt.subplots(figsize=(10, 6))
                
                # ç»˜åˆ¶ç³»æ•°æ¡å½¢å›¾
                colors = ['#1f77b4', '#ff7f0e']
                bars = ax.bar(feature_names, model.coef_, color=colors, alpha=0.7)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, coef in zip(bars, model.coef_):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + (0.001 if height >= 0 else -0.001),
                            f'{coef:.4f}', ha='center', va='bottom' if height >= 0 else 'top')
                
                # æ·»åŠ é›¶çº¿
                ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title('å›å½’ç³»æ•°åˆ†æ', fontsize=14)
                ax.set_ylabel('ç³»æ•°å€¼', fontsize=12)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3, axis='y')
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºé¢„æµ‹å€¼ä¸å®é™…å€¼çš„å¯¹æ¯”
                fig, ax = plt.subplots(figsize=(10, 6))
                
                # ç»˜åˆ¶æ•£ç‚¹å›¾
                ax.scatter(y, y_pred, alpha=0.7, s=60, c='blue', edgecolors='w', linewidth=0.5)
                
                # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
                min_val = min(y.min(), y_pred.min())
                max_val = max(y.max(), y_pred.max())
                ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹çº¿')
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title('é¢„æµ‹å€¼ä¸å®é™…å€¼å¯¹æ¯”', fontsize=14)
                ax.set_xlabel('å®é™…æ”¶ç›Šç‡(%)', fontsize=12)
                ax.set_ylabel('é¢„æµ‹æ”¶ç›Šç‡(%)', fontsize=12)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹
                ax.legend()
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºæ®‹å·®åˆ†æ
                residuals = y - y_pred
                
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                
                # æ®‹å·®ç›´æ–¹å›¾
                ax1.hist(residuals, bins=20, edgecolor='black', alpha=0.7)
                ax1.set_title('æ®‹å·®åˆ†å¸ƒ', fontsize=14)
                ax1.set_xlabel('æ®‹å·®', fontsize=12)
                ax1.set_ylabel('é¢‘æ•°', fontsize=12)
                ax1.grid(True, alpha=0.3)
                
                # æ®‹å·®æ•£ç‚¹å›¾
                ax2.scatter(y_pred, residuals, alpha=0.7, s=60, c='blue', edgecolors='w', linewidth=0.5)
                ax2.axhline(y=0, color='r', linestyle='--')
                ax2.set_title('æ®‹å·®ä¸é¢„æµ‹å€¼å…³ç³»', fontsize=14)
                ax2.set_xlabel('é¢„æµ‹æ”¶ç›Šç‡(%)', fontsize=12)
                ax2.set_ylabel('æ®‹å·®', fontsize=12)
                ax2.grid(True, alpha=0.3)
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºæ®‹å·®ç»Ÿè®¡
                st.write('ğŸ“Š æ®‹å·®åˆ†æï¼š')
                st.write(f'- æ®‹å·®å‡å€¼ï¼š{residuals.mean():.6f}')
                st.write(f'- æ®‹å·®æ ‡å‡†å·®ï¼š{residuals.std():.6f}')
                st.write(f'- æ®‹å·®æœ€å°å€¼ï¼š{residuals.min():.6f}')
                st.write(f'- æ®‹å·®æœ€å¤§å€¼ï¼š{residuals.max():.6f}')
                
                # æ£€æŸ¥æ®‹å·®æ˜¯å¦æ¥è¿‘æ­£æ€åˆ†å¸ƒ
                if abs(residuals.mean()) < 0.01:
                    st.write('- æ®‹å·®å‡å€¼æ¥è¿‘0ï¼Œæ¨¡å‹æ— å')
                else:
                    st.write('- æ®‹å·®å‡å€¼åç¦»0ï¼Œæ¨¡å‹å¯èƒ½å­˜åœ¨åå·®')
    except Exception as e:
        st.error(f'å›å½’åˆ†ææ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # å…¸å‹è¯„è®ºå±•ç¤º
    st.subheader('å…¸å‹è¯„è®ºå±•ç¤º')
    
    try:
        if filtered_comments.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„è¯„è®ºæ•°æ®ã€‚')
        else:
            # è·å–ç§¯æå’Œæ¶ˆæè¯„è®º
            positive_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == 'ç§¯æ'].sort_values('llm_sentiment_score', ascending=False)
            negative_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == 'æ¶ˆæ'].sort_values('llm_sentiment_score', ascending=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("### ğŸŸ¢ ç§¯æè¯„è®ºï¼ˆæƒ…æ„Ÿå¾—åˆ†æœ€é«˜ï¼‰")
                
                # æ˜¾ç¤ºå‰5æ¡ç§¯æè¯„è®º
                for i, (_, row) in enumerate(positive_comments.head(5).iterrows()):
                    st.write(f"**è¯„è®º {i+1}** (å¾—åˆ†: {row['llm_sentiment_score']:.3f})")
                    st.write(f"{row['combined_text']}")
                    st.write(f"*å‘å¸ƒæ—¶é—´: {row['post_publish_time'].strftime('%Y-%m-%d %H:%M')}*")
                    st.write("---")
            
            with col2:
                st.write("### ğŸ”´ æ¶ˆæè¯„è®ºï¼ˆæƒ…æ„Ÿå¾—åˆ†æœ€ä½ï¼‰")
                
                # æ˜¾ç¤ºå‰5æ¡æ¶ˆæè¯„è®º
                for i, (_, row) in enumerate(negative_comments.head(5).iterrows()):
                    st.write(f"**è¯„è®º {i+1}** (å¾—åˆ†: {row['llm_sentiment_score']:.3f})")
                    st.write(f"{row['combined_text']}")
                    st.write(f"*å‘å¸ƒæ—¶é—´: {row['post_publish_time'].strftime('%Y-%m-%d %H:%M')}*")
                    st.write("---")
    except Exception as e:
        st.error(f'æ˜¾ç¤ºå…¸å‹è¯„è®ºæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºæƒ…æ„Ÿè¯å…¸ç»Ÿè®¡
    st.subheader('æƒ…æ„Ÿè¯å…¸ç»Ÿè®¡')
    
    try:
        # åŠ è½½æƒ…æ„Ÿè¯å…¸
        positive_words, negative_words = load_sentiment_dictionaries()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"### ç§¯æè¯å…¸")
            st.write(f"- è¯å…¸å¤§å°: {len(positive_words)} ä¸ªè¯è¯­")
            st.write("- ç¤ºä¾‹è¯è¯­:")
            # æ˜¾ç¤ºå‰10ä¸ªç§¯æè¯è¯­
            for word in positive_words[:10]:
                st.write(f"  - {word}")
            if len(positive_words) > 10:
                st.write(f"  - ... è¿˜æœ‰ {len(positive_words)-10} ä¸ªè¯è¯­")
        
        with col2:
            st.write(f"### æ¶ˆæè¯å…¸")
            st.write(f"- è¯å…¸å¤§å°: {len(negative_words)} ä¸ªè¯è¯­")
            st.write("- ç¤ºä¾‹è¯è¯­:")
            # æ˜¾ç¤ºå‰10ä¸ªæ¶ˆæè¯è¯­
            for word in negative_words[:10]:
                st.write(f"  - {word}")
            if len(negative_words) > 10:
                st.write(f"  - ... è¿˜æœ‰ {len(negative_words)-10} ä¸ªè¯è¯­")
        
        # åˆ†æè¯„è®ºä¸­çš„æƒ…æ„Ÿè¯ä½¿ç”¨æƒ…å†µ
        if not filtered_comments.empty:
            # ç»Ÿè®¡è¯„è®ºä¸­å‡ºç°çš„ç§¯æå’Œæ¶ˆæè¯è¯­
            pos_word_counts = Counter()
            neg_word_counts = Counter()
            
            for text in filtered_comments['combined_text']:
                for word in positive_words:
                    if word in text:
                        pos_word_counts[word] += 1
                for word in negative_words:
                    if word in text:
                        neg_word_counts[word] += 1
            
            # æ˜¾ç¤ºæœ€å¸¸è§çš„æƒ…æ„Ÿè¯
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("### æœ€å¸¸è§çš„ç§¯æè¯è¯­")
                if pos_word_counts:
                    for word, count in pos_word_counts.most_common(10):
                        st.write(f"- {word}: {count} æ¬¡")
                else:
                    st.write("è¯„è®ºä¸­æœªå‘ç°ç§¯æè¯è¯­")
            
            with col2:
                st.write("### æœ€å¸¸è§çš„æ¶ˆæè¯è¯­")
                if neg_word_counts:
                    for word, count in neg_word_counts.most_common(10):
                        st.write(f"- {word}: {count} æ¬¡")
                else:
                    st.write("è¯„è®ºä¸­æœªå‘ç°æ¶ˆæè¯è¯­")
    except Exception as e:
        st.error(f'æ˜¾ç¤ºæƒ…æ„Ÿè¯å…¸ç»Ÿè®¡æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥è¯å…¸æ–‡ä»¶æ˜¯å¦å­˜åœ¨æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚')

except Exception as e:
    st.error(f'åº”ç”¨ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    st.write('è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚')

# é¡µè„š
st.markdown('---')
st.markdown('**ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æåº”ç”¨**')
st.markdown('åŸºäºStreamlitæ„å»ºçš„æƒ…æ„Ÿåˆ†æä¸è‚¡ç¥¨æ”¶ç›Šç‡å…³ç³»ç ”ç©¶å·¥å…·')
