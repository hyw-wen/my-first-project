import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, RANSACRegressor
import warnings
import os
import requests
from collections import Counter
import re
import matplotlib.font_manager as fm

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º - ä¿®å¤äº‘ç«¯ä¸­æ–‡ä¹±ç é—®é¢˜
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œè§£å†³äº‘ç«¯ç¯å¢ƒä¸­æ–‡æ˜¾ç¤ºé—®é¢˜"""
    try:
        # å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
    except:
        # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False

setup_chinese_font()
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½æƒ…æ„Ÿè¯å…¸ - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def load_sentiment_dictionaries():
    """
    åŠ è½½ç”¨æˆ·æä¾›çš„æƒ…æ„Ÿè¯å…¸
    ç§¯æè¯å…¸ï¼šzhang_unformal_pos (1).txt
    æ¶ˆæè¯å…¸ï¼šzhang_unformal_neg (1).txt
    """
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ„å»ºè¯å…¸æ–‡ä»¶è·¯å¾„
    pos_dict_path = os.path.join(script_dir, 'zhang_unformal_pos (1).txt')
    neg_dict_path = os.path.join(script_dir, 'zhang_unformal_neg (1).txt')
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(pos_dict_path) or not os.path.exists(neg_dict_path):
        st.error(f"æƒ…æ„Ÿè¯å…¸æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- {pos_dict_path}\n- {neg_dict_path}")
        st.stop()
    
    # åŠ è½½ç§¯æè¯å…¸
    with open(pos_dict_path, 'r', encoding='utf-8') as f:
        positive_words = [line.strip() for line in f if line.strip()]
    
    # åŠ è½½æ¶ˆæè¯å…¸
    with open(neg_dict_path, 'r', encoding='utf-8') as f:
        negative_words = [line.strip() for line in f if line.strip()]
    
    return positive_words, negative_words

# å®ç°åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
def lexicon_based_sentiment_analysis(text, pos_words, neg_words):
    """
    åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    text: è¯„è®ºæ–‡æœ¬
    pos_words: ç§¯æè¯è¯­åˆ—è¡¨
    neg_words: æ¶ˆæè¯è¯­åˆ—è¡¨
    è¿”å›ï¼š
    - sentiment_label: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰
    - sentiment_score: æƒ…æ„Ÿå¾—åˆ†ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
    """
    if pd.isna(text) or text.strip() == '':
        return 'ä¸­æ€§', 0.0
    
    # è®¡ç®—ç§¯æè¯è¯­å’Œæ¶ˆæè¯è¯­çš„å‡ºç°æ¬¡æ•°
    pos_count = sum(1 for word in pos_words if word in text)
    neg_count = sum(1 for word in neg_words if word in text)
    
    # è®¡ç®—æƒ…æ„Ÿå¾—åˆ†
    total = pos_count + neg_count + 1  # åŠ 1é¿å…é™¤ä»¥0
    sentiment_score = (pos_count - neg_count) / total
    
    # ç¡®å®šæƒ…æ„Ÿæ ‡ç­¾
    if sentiment_score > 0.1:
        sentiment_label = 'ç§¯æ'
    elif sentiment_score < -0.1:
        sentiment_label = 'æ¶ˆæ'
    else:
        sentiment_label = 'ä¸­æ€§'
    
    return sentiment_label, sentiment_score

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title('ä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæƒ…æ„Ÿåˆ†æ')

# åŠ è½½æ•°æ® - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def load_data():
    # åŠ è½½è¯„è®ºå’Œæƒ…æ„Ÿåˆ†ææ•°æ®
    # ä¼˜å…ˆä½¿ç”¨æ›´æ–°åçš„æƒ…æ„Ÿåˆ†æç»“æœæ–‡ä»¶
    updated_file = "300059_sentiment_analysis_updated.csv"
    original_file = "300059_sentiment_analysis.csv"
    
    try:
        if os.path.exists(updated_file):
            comments_df = pd.read_csv(updated_file)
            st.success(f"å·²åŠ è½½æ”¹è¿›çš„æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
        elif os.path.exists(original_file):
            comments_df = pd.read_csv(original_file)
            st.info(f"å·²åŠ è½½åŸå§‹æƒ…æ„Ÿåˆ†æç»“æœï¼ˆ{len(comments_df)}æ¡è¯„è®ºï¼‰")
        else:
            st.error("æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- 300059_sentiment_analysis_updated.csv\n- 300059_sentiment_analysis.csv")
            st.stop()
        
        comments_df['post_publish_time'] = pd.to_datetime(comments_df['post_publish_time'])
        
        # åŠ è½½ä»·æ ¼æ•°æ®
        price_file = "300059_price_data.csv"
        if os.path.exists(price_file):
            price_df = pd.read_csv(price_file)
            price_df['trade_date'] = pd.to_datetime(price_df['trade_date'])
        else:
            st.error("æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äºåº”ç”¨ç›®å½•ä¸­ï¼š\n- 300059_price_data.csv")
            st.stop()
        
        return comments_df, price_df
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        st.stop()

# å¤„ç†æ•°æ® - ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿å‚æ•°æ›´æ–°ç”Ÿæ•ˆ
def process_data(comments_df, price_df, text_length_limit=500, window_size=30, lag_days=0):
    # å¤„ç†combined_textå­—æ®µä¸ºç©ºçš„æƒ…å†µ
    filtered_comments = comments_df.copy()
    
    # è°ƒæ•´æ–‡æœ¬å­—æ®µä¼˜å…ˆçº§ï¼šä¼˜å…ˆä½¿ç”¨post_titleï¼Œå†ä½¿ç”¨combined_textå’Œprocessed_content
    if 'post_title' in filtered_comments.columns:
        filtered_comments['combined_text'] = filtered_comments['post_title']
    elif 'combined_text' in filtered_comments.columns:
        filtered_comments['combined_text'] = filtered_comments['combined_text']
    else:
        st.error("æ•°æ®ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æœ¬åˆ—ï¼ˆpost_titleæˆ–combined_textï¼‰")
        return pd.DataFrame(), pd.DataFrame()
    
    # è¿‡æ»¤æ— æ•ˆè¯„è®ºå†…å®¹
    invalid_pattern = r'(å›¾ç‰‡å›¾ç‰‡|è½¬å‘è½¬å‘|^[!ï¼]{5,}$|^[?ï¼Ÿ]{5,}$|^\.{5,}$|^\s*$)'
    filtered_comments = filtered_comments[~filtered_comments['combined_text'].str.contains(invalid_pattern, na=False, regex=True)]
    
    # åŠ è½½æƒ…æ„Ÿè¯å…¸
    try:
        positive_words, negative_words = load_sentiment_dictionaries()
    except Exception as e:
        st.error(f"åŠ è½½æƒ…æ„Ÿè¯å…¸å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame(), pd.DataFrame()
    
    # åº”ç”¨åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
    sentiment_results = filtered_comments['combined_text'].apply(
        lambda x: lexicon_based_sentiment_analysis(x, positive_words, negative_words)
    )
    
    # å°†ç»“æœæ‹†åˆ†ä¸ºæƒ…æ„Ÿæ ‡ç­¾å’Œæƒ…æ„Ÿå¾—åˆ†
    filtered_comments['llm_sentiment_label'] = sentiment_results.str[0]
    filtered_comments['llm_sentiment_score'] = sentiment_results.str[1]
    filtered_comments['ensemble_sentiment_score'] = sentiment_results.str[1]
    filtered_comments['lexicon_sentiment'] = sentiment_results.str[1]
    
    # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
    filtered_comments['text_length'] = filtered_comments['combined_text'].str.len()
    filtered_comments = filtered_comments[(filtered_comments['text_length'] >= 1) & (filtered_comments['text_length'] <= text_length_limit)]
    
    # æŒ‰æ—¥æœŸèšåˆæƒ…æ„Ÿæ•°æ®
    daily_sentiment = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date).agg({
        'ensemble_sentiment_score': ['mean', 'median', 'std', 'count'],
        'llm_sentiment_score': 'mean',
        'lexicon_sentiment': 'mean'
    }).reset_index()
    
    # é‡å‘½ååˆ—
    daily_sentiment.columns = ['date', 'ensemble_mean', 'ensemble_median', 'ensemble_std', 'comment_count', 'llm_mean', 'lexicon_mean']
    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
    
    # åˆå¹¶ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨å·¦è¿æ¥ï¼Œä¿ç•™æ‰€æœ‰ä»·æ ¼æ—¥æœŸï¼‰
    merged_df = pd.merge(price_df, daily_sentiment, left_on='trade_date', right_on='date', how='left')
    
    # å¤„ç†æ²¡æœ‰è¯„è®ºçš„æ—¥æœŸï¼ˆå¡«å……NaNå€¼ï¼‰
    merged_df['comment_count'] = merged_df['comment_count'].fillna(0)
    merged_df['ensemble_mean'] = merged_df['ensemble_mean'].fillna(0)
    merged_df['ensemble_median'] = merged_df['ensemble_median'].fillna(0)
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    merged_df['llm_mean'] = merged_df['llm_mean'].fillna(0)
    merged_df['lexicon_mean'] = merged_df['lexicon_mean'].fillna(0)
    
    # ç¡®ä¿stdåˆ—ä¸ä¸ºNaN
    merged_df['ensemble_std'] = merged_df['ensemble_std'].fillna(0)
    
    # æ·»åŠ æ»åæƒ…æ„Ÿæ•°æ®
    if lag_days > 0:
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean'].shift(lag_days)
        merged_df['comment_count_lag'] = merged_df['comment_count'].shift(lag_days)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std'].shift(lag_days)
        merged_df['ensemble_mean_lag'] = merged_df['ensemble_mean_lag'].fillna(0)
        merged_df['comment_count_lag'] = merged_df['comment_count_lag'].fillna(0)
        merged_df['ensemble_std_lag'] = merged_df['ensemble_std_lag'].fillna(0)
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡
    if window_size > 1:
        merged_df['ensemble_mean_rolling'] = merged_df['ensemble_mean'].rolling(window=window_size).mean()
        merged_df['next_day_return_rolling'] = merged_df['next_day_return'].rolling(window=window_size).mean()
    
    return merged_df, filtered_comments

# ä¾§è¾¹æ ï¼šå‚æ•°è°ƒæ•´
st.sidebar.subheader('å‚æ•°è°ƒæ•´')

# ä½¿ç”¨session_stateç®¡ç†å‚æ•°çŠ¶æ€
if 'text_length' not in st.session_state:
    st.session_state.text_length = 500
if 'window_size' not in st.session_state:
    st.session_state.window_size = 30
if 'lag_days' not in st.session_state:
    st.session_state.lag_days = 0

# é‡ç½®æŒ‰é’®
if st.sidebar.button('ğŸ”„ é‡ç½®æ‰€æœ‰å‚æ•°'):
    st.session_state.text_length = 500
    st.session_state.window_size = 30
    st.session_state.lag_days = 0
    st.experimental_rerun()

text_length = st.sidebar.slider('æ–‡æœ¬é•¿åº¦é™åˆ¶', 50, 1000, st.session_state.text_length, step=50, key='length_slider')
window_size = st.sidebar.slider('ç§»åŠ¨å¹³å‡çª—å£å¤§å°(å¤©)', 1, 90, st.session_state.window_size, step=5, key='window_slider')
lag_days = st.sidebar.slider('æƒ…æ„Ÿæ»åå¤©æ•°', 0, 10, st.session_state.lag_days, step=1, key='lag_slider')

# æ›´æ–°session_state
st.session_state.text_length = text_length
st.session_state.window_size = window_size
st.session_state.lag_days = lag_days

# åŠ è½½å’Œå¤„ç†æ•°æ®
try:
    comments_df, price_df = load_data()
    merged_df, filtered_comments = process_data(comments_df, price_df, text_length, window_size, lag_days)
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    st.subheader('æ•°æ®è´¨é‡æ£€æŸ¥')
    
    # æ£€æŸ¥è¯„è®ºæ•°é‡
    total_comments = len(comments_df)
    filtered_count = len(filtered_comments)
    filtered_out_count = total_comments - filtered_count
    zero_sentiment = (comments_df['ensemble_sentiment_score'] == 0).sum()
    
    st.write(f'ğŸ“Š æ•°æ®æ¦‚è§ˆï¼š')
    st.write(f'- å…±æ”¶é›†åˆ° {total_comments} æ¡è¯„è®º')
    st.write(f'- ç»è¿‡è¿‡æ»¤åä¿ç•™ï¼š{filtered_count} æ¡æœ‰æ•ˆè¯„è®º')
    st.write(f'- è¿‡æ»¤æ‰çš„è¯„è®ºï¼š{filtered_out_count} æ¡ï¼ˆå†…å®¹æ— æ•ˆæˆ–ä¸ç¬¦åˆé•¿åº¦è¦æ±‚ï¼‰')
    st.write(f'- ä¸­æ€§æƒ…æ„Ÿè¯„è®ºï¼ˆåˆ†æ•°ä¸º0ï¼‰ï¼š{zero_sentiment} æ¡')
    st.write(f'- ä¿ç•™çš„äº¤æ˜“æ—¥æ•°æ®ï¼š{len(merged_df)} ä¸ª')
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    if filtered_count < total_comments * 0.5:
        st.warning(f'æ³¨æ„ï¼šæœ‰ {filtered_out_count} æ¡è¯„è®ºè¢«è¿‡æ»¤ï¼Œä¿ç•™çš„æœ‰æ•ˆæ ·æœ¬è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    if zero_sentiment > total_comments * 0.8:
        st.warning(f'æ³¨æ„ï¼š{zero_sentiment/total_comments:.1%} çš„è¯„è®ºæƒ…æ„Ÿåˆ†æ•°ä¸º0ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœçš„å‡†ç¡®æ€§ã€‚')
    
    # æ£€æŸ¥æ—¥æœŸèŒƒå›´
    if not merged_df.empty:
        date_range = f'{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}'
        st.write(f'- æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{date_range}')
    
    # æ˜¾ç¤ºè¯„è®ºæ•°é‡éšæ—¶é—´çš„å˜åŒ–
    st.subheader('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–')
    
    try:
        # æŒ‰æ—¥æœŸåˆ†ç»„å¹¶è®¡ç®—è¯„è®ºæ•°é‡
        daily_comments = comments_df.groupby(comments_df['post_publish_time'].dt.date)['post_id'].count()
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(daily_comments) > 0:
            # ç»˜åˆ¶æŠ˜çº¿å›¾
            daily_comments.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=5, color='#1f77b4')
            
            # æ·»åŠ æ¯æ—¥è¯„è®ºæ•°é‡æ ‡ç­¾
            for x, y in zip(daily_comments.index, daily_comments.values):
                ax.text(x, y + 0.5, str(y), ha='center', va='bottom', fontsize=9)
            
            # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡å˜åŒ–è¶‹åŠ¿', fontsize=14)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
            
            # è°ƒæ•´Yè½´èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰ç‚¹éƒ½èƒ½æ˜¾ç¤º
            ax.set_ylim(0, daily_comments.max() * 1.1)
            
            # æ·»åŠ ç½‘æ ¼çº¿
            ax.grid(True, alpha=0.3)
            
            # è°ƒæ•´æ—¥æœŸæ ‡ç­¾
            plt.xticks(rotation=45, fontsize=10)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_daily = daily_comments.mean()
            max_daily = daily_comments.max()
            min_daily = daily_comments.min()
            
            # åœ¨å›¾è¡¨ä¸­æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            stats_text = f'å¹³å‡æ—¥è¯„è®ºæ•°: {avg_daily:.1f}\næœ€é«˜æ—¥è¯„è®ºæ•°: {max_daily}\næœ€ä½æ—¥è¯„è®ºæ•°: {min_daily}'
            ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8), fontsize=10)
        else:
            ax.set_title('æš‚æ— è¯„è®ºæ•°æ®', fontsize=14)
            ax.text(0.5, 0.5, 'æ²¡æœ‰è¶³å¤Ÿçš„è¯„è®ºæ•°æ®æ¥ç»˜åˆ¶è¶‹åŠ¿å›¾', transform=ax.transAxes, ha='center', va='center', fontsize=12)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.pyplot(fig)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if len(daily_comments) > 0:
            st.write(f'ğŸ“Š è¯„è®ºæ•°é‡ç»Ÿè®¡ï¼š')
            st.write(f'- è¯„è®ºæ—¥æœŸèŒƒå›´ï¼š{daily_comments.index.min()} è‡³ {daily_comments.index.max()}')
            st.write(f'- æœ‰è¯„è®ºçš„å¤©æ•°ï¼š{len(daily_comments)} å¤©')
            st.write(f'- å¹³å‡æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.mean():.1f} æ¡')
            st.write(f'- æœ€é«˜æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.max()} æ¡')
            st.write(f'- æœ€ä½æ¯æ—¥è¯„è®ºæ•°ï¼š{daily_comments.min()} æ¡')
        else:
            st.warning('æ²¡æœ‰è¯„è®ºæ•°æ®å¯æ˜¾ç¤ºã€‚')
    except Exception as e:
        st.error(f'ç»˜åˆ¶è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æç»“æœ
    st.subheader('æƒ…æ„Ÿåˆ†æç»“æœ')
    
    col1, col2 = st.columns(2)
    
    with col1:
        # LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ
        st.write('### æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ')
        try:
            # æ£€æŸ¥æƒ…æ„Ÿæ ‡ç­¾åˆ—æ˜¯å¦å­˜åœ¨ä¸”éç©º
            if 'llm_sentiment_label' in comments_df.columns:
                sentiment_counts = comments_df['llm_sentiment_label'].value_counts()
                
                if len(sentiment_counts) > 0:
                    # åˆ›å»ºé¥¼å›¾
                    fig, ax = plt.subplots(figsize=(8, 6))
                    
                    # è®¾ç½®é¥¼å›¾é¢œè‰²
                    colors = ['#4caf50' if label == 'ç§¯æ' else '#ff9800' if label == 'ä¸­æ€§' else '#f44336' for label in sentiment_counts.index]
                    
                    # ç»˜åˆ¶é¥¼å›¾
                    patches, texts, autotexts = ax.pie(
                        sentiment_counts.values, 
                        labels=sentiment_counts.index, 
                        autopct='%1.1f%%', 
                        startangle=90, 
                        colors=colors, 
                        wedgeprops={'edgecolor': 'white', 'linewidth': 1}, 
                        textprops={'fontsize': 12}
                    )
                    
                    # è®¾ç½®ç™¾åˆ†æ¯”æ ‡ç­¾é¢œè‰²å’Œå¤§å°
                    for autotext in autotexts:
                        autotext.set_color('white')
                        autotext.set_fontsize(11)
                    
                    # è®¾ç½®æ ‡é¢˜
                    ax.set_title('LLMæƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ', fontsize=14)
                    
                    # ç¡®ä¿é¥¼å›¾æ˜¯åœ†å½¢
                    ax.axis('equal')
                    
                    # æ˜¾ç¤ºå›¾è¡¨
                    st.pyplot(fig)
                    
                    # æ˜¾ç¤ºå…·ä½“æ•°é‡
                    st.write('æƒ…æ„Ÿæ ‡ç­¾æ•°é‡ï¼š')
                    for label, count in sentiment_counts.items():
                        st.write(f'- {label}: {count} æ¡ ({count/len(comments_df)*100:.1f}%)')
                else:
                    st.write('æš‚æ— æƒ…æ„Ÿæ ‡ç­¾æ•°æ®')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰æƒ…æ„Ÿæ ‡ç­¾åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    with col2:
        # èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
        st.write('### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
        try:
            # æ£€æŸ¥æƒ…æ„Ÿå¾—åˆ†åˆ—æ˜¯å¦å­˜åœ¨
            if 'ensemble_sentiment_score' in comments_df.columns:
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                mean_score = comments_df['ensemble_sentiment_score'].mean()
                median_score = comments_df['ensemble_sentiment_score'].median()
                std_score = comments_df['ensemble_sentiment_score'].std()
                
                # åˆ›å»ºç›´æ–¹å›¾
                fig, ax = plt.subplots(figsize=(8, 6))
                
                # ç»˜åˆ¶ç›´æ–¹å›¾
                sns.histplot(
                    comments_df['ensemble_sentiment_score'], 
                    bins=20, 
                    kde=True, 
                    ax=ax, 
                    color='#1f77b4', 
                    edgecolor='w'
                )
                
                # æ·»åŠ å‡å€¼å’Œä¸­ä½æ•°çº¿
                ax.axvline(mean_score, color='red', linestyle='--', label=f'å‡å€¼: {mean_score:.2f}')
                ax.axvline(median_score, color='green', linestyle='--', label=f'ä¸­ä½æ•°: {median_score:.2f}')
                
                # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title('èåˆæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ', fontsize=14)
                ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
                ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
                
                # æ·»åŠ ç½‘æ ¼çº¿
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹
                ax.legend()
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write('æƒ…æ„Ÿå¾—åˆ†ç»Ÿè®¡ï¼š')
                st.write(f'- å‡å€¼: {mean_score:.4f}')
                st.write(f'- ä¸­ä½æ•°: {median_score:.4f}')
                st.write(f'- æ ‡å‡†å·®: {std_score:.4f}')
                st.write(f'- æœ€å°å€¼: {comments_df["ensemble_sentiment_score"].min():.4f}')
                st.write(f'- æœ€å¤§å€¼: {comments_df["ensemble_sentiment_score"].max():.4f}')
            else:
                st.write('æ•°æ®ä¸­æ²¡æœ‰èåˆæƒ…æ„Ÿå¾—åˆ†åˆ—')
        except Exception as e:
            st.error(f'ç»˜åˆ¶æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    
    # æ˜¾ç¤ºå¹³å‡æƒ…æ„Ÿä¸æ¬¡æ—¥æ”¶ç›Šç‡çš„å…³ç³»
    st.subheader('æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»åˆ†æ')
    
    try:
        if merged_df.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æã€‚')
        else:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿè¿›è¡Œåˆ†æ
            if len(merged_df) < 1:
                st.warning('æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œä»…æ˜¾ç¤ºåŸºæœ¬æ•°æ®æ¦‚è§ˆã€‚')
                
                # æ˜¾ç¤ºåŸºæœ¬æ•°æ®ä¿¡æ¯
                st.write(f'æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{merged_df["trade_date"].min().strftime("%Y-%m-%d")} è‡³ {merged_df["trade_date"].max().strftime("%Y-%m-%d")}')
                st.write(f'æœ‰æ•ˆäº¤æ˜“æ—¥æ•°é‡ï¼š{len(merged_df)} ä¸ª')
                st.write(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{merged_df["ensemble_mean"].mean():.4f}')
                st.write(f'å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{merged_df["next_day_return"].mean():.4f}%')
            else:
                # å³ä½¿æ•°æ®æœ‰é™ï¼Œä¹Ÿå°è¯•æ˜¾ç¤ºåŸºæœ¬æ•£ç‚¹å›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                
                if lag_days > 0:
                    scatter_x = merged_df['ensemble_mean_lag'] if 'ensemble_mean_lag' in merged_df.columns else merged_df['ensemble_mean']
                else:
                    scatter_x = merged_df['ensemble_mean']
                scatter_y = merged_df['next_day_return']
                
                # è¿‡æ»¤æ‰NaNå€¼
                valid_mask = scatter_x.notna() & scatter_y.notna()
                filtered_x = scatter_x[valid_mask]
                filtered_y = scatter_y[valid_mask]
                
                if len(filtered_x) < 1:
                    st.warning(f'æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼ˆ{len(filtered_x)}ä¸ªæ ·æœ¬ï¼‰ï¼Œä»…æ˜¾ç¤ºåŸºæœ¬å›¾è¡¨ã€‚')
                    ax.text(0.5, 0.5, f'ä»…æ‰¾åˆ°{len(filtered_x)}ä¸ªæœ‰æ•ˆæ ·æœ¬ç‚¹', transform=ax.transAxes, ha='center', va='center', fontsize=12)
                    ax.set_title('æ•°æ®ä¸è¶³', fontsize=14)
                else:
                    # ç»˜åˆ¶æ•£ç‚¹å›¾
                    ax.scatter(filtered_x, filtered_y, alpha=0.7, color='blue', s=60)
                    
                    # æ·»åŠ è¶‹åŠ¿çº¿
                    if len(filtered_x) >= 2:
                        z = np.polyfit(filtered_x, filtered_y, 1)
                        p = np.poly1d(z)
                        ax.plot(filtered_x, p(filtered_x), "r--", alpha=0.8)
                        
                        # è®¡ç®—ç›¸å…³ç³»æ•°
                        correlation = np.corrcoef(filtered_x, filtered_y)[0, 1]
                        ax.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {correlation:.3f}', transform=ax.transAxes, 
                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
                    
                    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
                    lag_text = f"ï¼ˆ{lag_days}å¤©æ»åï¼‰" if lag_days > 0 else ""
                    ax.set_title(f'å¹³å‡æƒ…æ„Ÿå¾—åˆ†ä¸æ¬¡æ—¥æ”¶ç›Šç‡å…³ç³»{lag_text}', fontsize=14)
                    ax.set_xlabel('å¹³å‡æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
                    ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡(%)', fontsize=12)
                    
                    # æ·»åŠ ç½‘æ ¼çº¿
                    ax.grid(True, alpha=0.3)
                
                # è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # æ˜¾ç¤ºå›¾è¡¨
                st.pyplot(fig)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if len(filtered_x) >= 1:
                    st.write(f'ğŸ“Š å…³ç³»åˆ†æç»Ÿè®¡ï¼š')
                    st.write(f'- æœ‰æ•ˆæ ·æœ¬æ•°ï¼š{len(filtered_x)} ä¸ª')
                    if len(filtered_x) >= 2:
                        st.write(f'- ç›¸å…³ç³»æ•°ï¼š{correlation:.4f}')
                    st.write(f'- å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{filtered_x.mean():.4f}')
                    st.write(f'- å¹³å‡æ¬¡æ—¥æ”¶ç›Šç‡ï¼š{filtered_y.mean():.4f}%')
    except Exception as e:
        st.error(f'ç»˜åˆ¶æƒ…æ„Ÿä¸æ”¶ç›Šç‡å…³ç³»å›¾æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # å›å½’åˆ†æ
    st.subheader('å›å½’åˆ†æ')
    
    try:
        if merged_df.empty or len(merged_df) < 2:
            st.warning('æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›å½’åˆ†æã€‚')
        else:
            # å‡†å¤‡å›å½’æ•°æ®
            if lag_days > 0:
                x_col = 'ensemble_mean_lag' if 'ensemble_mean_lag' in merged_df.columns else 'ensemble_mean'
                count_col = 'comment_count_lag' if 'comment_count_lag' in merged_df.columns else 'comment_count'
            else:
                x_col = 'ensemble_mean'
                count_col = 'comment_count'
            
            # è¿‡æ»¤NaNå€¼
            regression_df = merged_df[[x_col, count_col, 'next_day_return']].dropna()
            
            if len(regression_df) < 2:
                st.warning('æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›å½’åˆ†æã€‚')
            else:
                # å•å˜é‡å›å½’ï¼ˆæƒ…æ„Ÿå¾—åˆ†ï¼‰
                X = regression_df[[x_col]]
                y = regression_df['next_day_return']
                
                model = LinearRegression()
                model.fit(X, y)
                r2 = model.score(X, y)
                
                # åŒå˜é‡å›å½’ï¼ˆæƒ…æ„Ÿå¾—åˆ† + è¯„è®ºæ•°é‡ï¼‰
                X2 = regression_df[[x_col, count_col]]
                model2 = LinearRegression()
                model2.fit(X2, y)
                r2_2 = model2.score(X2, y)
                
                # æ˜¾ç¤ºå›å½’ç»“æœ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write('### å•å˜é‡å›å½’ï¼ˆæƒ…æ„Ÿå¾—åˆ†ï¼‰')
                    st.write(f'- RÂ²: {r2:.4f}')
                    st.write(f'- å›å½’ç³»æ•°: {model.coef_[0]:.6f}')
                    st.write(f'- æˆªè·: {model.intercept_:.6f}')
                    
                    # åˆ›å»ºå›å½’å›¾
                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.scatter(regression_df[x_col], regression_df['next_day_return'], alpha=0.7)
                    ax.plot(regression_df[x_col], model.predict(X), color='red', linewidth=2)
                    ax.set_xlabel('å¹³å‡æƒ…æ„Ÿå¾—åˆ†')
                    ax.set_ylabel('æ¬¡æ—¥æ”¶ç›Šç‡(%)')
                    ax.set_title('å•å˜é‡å›å½’ç»“æœ')
                    ax.grid(True, alpha=0.3)
                    plt.tight_layout()
                    st.pyplot(fig)
                
                with col2:
                    st.write('### åŒå˜é‡å›å½’ï¼ˆæƒ…æ„Ÿå¾—åˆ† + è¯„è®ºæ•°é‡ï¼‰')
                    st.write(f'- RÂ²: {r2_2:.4f}')
                    st.write(f'- æƒ…æ„Ÿå¾—åˆ†ç³»æ•°: {model2.coef_[0]:.6f}')
                    st.write(f'- è¯„è®ºæ•°é‡ç³»æ•°: {model2.coef_[1]:.6f}')
                    st.write(f'- æˆªè·: {model2.intercept_:.6f}')
                    
                    # åˆ›å»ºç³»æ•°æ¯”è¾ƒå›¾
                    fig, ax = plt.subplots(figsize=(8, 6))
                    coefficients = [model2.coef_[0], model2.coef_[1]]
                    labels = ['æƒ…æ„Ÿå¾—åˆ†', 'è¯„è®ºæ•°é‡']
                    colors = ['blue', 'green']
                    bars = ax.bar(labels, coefficients, color=colors)
                    ax.set_ylabel('å›å½’ç³»æ•°')
                    ax.set_title('åŒå˜é‡å›å½’ç³»æ•°æ¯”è¾ƒ')
                    ax.grid(True, alpha=0.3)
                    
                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, coeff in zip(bars, coefficients):
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + (0.000001 if height > 0 else -0.000001),
                               f'{coeff:.6f}', ha='center', va='bottom' if height > 0 else 'top')
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                
                # æ¨¡å‹æ¯”è¾ƒ
                st.write('### æ¨¡å‹æ¯”è¾ƒ')
                st.write(f'- å•å˜é‡æ¨¡å‹ RÂ²: {r2:.4f}')
                st.write(f'- åŒå˜é‡æ¨¡å‹ RÂ²: {r2_2:.4f}')
                improvement = ((r2_2 - r2) / r2 * 100) if r2 != 0 else 0
                st.write(f'- æ¨¡å‹æ”¹è¿›: {improvement:.2f}%')
                
                # ç»“è®º
                st.write('### ç»“è®º')
                if r2 > 0.1:
                    st.write('âœ… æƒ…æ„Ÿå¾—åˆ†å¯¹æ¬¡æ—¥æ”¶ç›Šç‡æœ‰è¾ƒå¼ºçš„é¢„æµ‹èƒ½åŠ›')
                elif r2 > 0.05:
                    st.write('âš ï¸ æƒ…æ„Ÿå¾—åˆ†å¯¹æ¬¡æ—¥æ”¶ç›Šç‡æœ‰ä¸€å®šçš„é¢„æµ‹èƒ½åŠ›')
                else:
                    st.write('âŒ æƒ…æ„Ÿå¾—åˆ†å¯¹æ¬¡æ—¥æ”¶ç›Šç‡çš„é¢„æµ‹èƒ½åŠ›è¾ƒå¼±')
                
                if r2_2 > r2:
                    st.write('âœ… åŠ å…¥è¯„è®ºæ•°é‡åï¼Œæ¨¡å‹é¢„æµ‹èƒ½åŠ›æœ‰æ‰€æå‡')
                else:
                    st.write('âš ï¸ åŠ å…¥è¯„è®ºæ•°é‡åï¼Œæ¨¡å‹é¢„æµ‹èƒ½åŠ›æå‡ä¸æ˜æ˜¾')
    except Exception as e:
        st.error(f'è¿›è¡Œå›å½’åˆ†ææ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')
    
    # å…¸å‹è¯„è®ºå±•ç¤º
    st.subheader('å…¸å‹è¯„è®ºå±•ç¤º')
    
    try:
        if filtered_comments.empty:
            st.warning('æ²¡æœ‰å¯ç”¨çš„è¯„è®ºæ•°æ®ã€‚')
        else:
            # è·å–ç§¯æå’Œæ¶ˆæè¯„è®º
            positive_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == 'ç§¯æ'].sort_values('llm_sentiment_score', ascending=False)
            negative_comments = filtered_comments[filtered_comments['llm_sentiment_label'] == 'æ¶ˆæ'].sort_values('llm_sentiment_score', ascending=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("### ğŸŸ¢ ç§¯æè¯„è®ºï¼ˆæƒ…æ„Ÿå¾—åˆ†æœ€é«˜ï¼‰")
                
                # æ˜¾ç¤ºå‰5æ¡ç§¯æè¯„è®º
                for i, (_, row) in enumerate(positive_comments.head(5).iterrows()):
                    st.write(f"**è¯„è®º {i+1}** (å¾—åˆ†: {row['llm_sentiment_score']:.3f})")
                    st.write(f"{row['combined_text']}")
                    st.write(f"*å‘å¸ƒæ—¶é—´: {row['post_publish_time'].strftime('%Y-%m-%d %H:%M')}*")
                    st.write("---")
            
            with col2:
                st.write("### ğŸ”´ æ¶ˆæè¯„è®ºï¼ˆæƒ…æ„Ÿå¾—åˆ†æœ€ä½ï¼‰")
                
                # æ˜¾ç¤ºå‰5æ¡æ¶ˆæè¯„è®º
                for i, (_, row) in enumerate(negative_comments.head(5).iterrows()):
                    st.write(f"**è¯„è®º {i+1}** (å¾—åˆ†: {row['llm_sentiment_score']:.3f})")
                    st.write(f"{row['combined_text']}")
                    st.write(f"*å‘å¸ƒæ—¶é—´: {row['post_publish_time'].strftime('%Y-%m-%d %H:%M')}*")
                    st.write("---")
            
            # æƒ…æ„Ÿå…³é”®è¯åˆ†æ
            st.write("### æƒ…æ„Ÿå…³é”®è¯åˆ†æ")
            
            # æå–ç§¯æå’Œæ¶ˆæè¯„è®ºä¸­çš„å…³é”®è¯
            positive_text = " ".join(positive_comments['combined_text'].tolist())
            negative_text = " ".join(negative_comments['combined_text'].tolist())
            
            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆåŸºäºè¯é¢‘ï¼‰
            # ä¸­æ–‡åˆ†è¯ç®€å•å¤„ç†ï¼ˆæŒ‰å­—ç¬¦åˆ†å‰²ï¼‰
            def extract_keywords(text, top_n=10):
                # ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œæ•°å­—
                text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z]', ' ', text)
                # åˆ†å‰²æˆå•è¯
                words = text.split()
                # è¿‡æ»¤æ‰å•å­—ç¬¦å’Œå¸¸è§åœç”¨è¯
                stop_words = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™']
                words = [word for word in words if len(word) > 1 and word not in stop_words]
                # ç»Ÿè®¡è¯é¢‘
                word_count = Counter(words)
                return word_count.most_common(top_n)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ç§¯æè¯„è®ºå…³é”®è¯**")
                pos_keywords = extract_keywords(positive_text)
                for word, count in pos_keywords:
                    st.write(f"- {word}: {count}æ¬¡")
            
            with col2:
                st.write("**æ¶ˆæè¯„è®ºå…³é”®è¯**")
                neg_keywords = extract_keywords(negative_text)
                for word, count in neg_keywords:
                    st.write(f"- {word}: {count}æ¬¡")
            
            # æƒ…æ„Ÿéšæ—¶é—´å˜åŒ–
            st.write("### æƒ…æ„Ÿéšæ—¶é—´å˜åŒ–")
            
            # æŒ‰æ—¥æœŸè®¡ç®—å¹³å‡æƒ…æ„Ÿå¾—åˆ†
            daily_sentiment_trend = filtered_comments.groupby(filtered_comments['post_publish_time'].dt.date)['llm_sentiment_score'].mean()
            
            fig, ax = plt.subplots(figsize=(12, 6))
            daily_sentiment_trend.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=5)
            
            # æ·»åŠ é›¶çº¿
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)
            
            # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title('æ¯æ—¥å¹³å‡æƒ…æ„Ÿå¾—åˆ†å˜åŒ–è¶‹åŠ¿', fontsize=14)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12)
            ax.set_ylabel('å¹³å‡æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
            
            # æ·»åŠ ç½‘æ ¼çº¿
            ax.grid(True, alpha=0.3)
            
            # è°ƒæ•´æ—¥æœŸæ ‡ç­¾
            plt.xticks(rotation=45, fontsize=10)
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
            
            # æ˜¾ç¤ºå›¾è¡¨
            st.pyplot(fig)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            avg_sentiment = daily_sentiment_trend.mean()
            max_sentiment_date = daily_sentiment_trend.idxmax()
            min_sentiment_date = daily_sentiment_trend.idxmin()
            
            st.write(f"ğŸ“Š æƒ…æ„Ÿè¶‹åŠ¿ç»Ÿè®¡ï¼š")
            st.write(f"- å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼š{avg_sentiment:.4f}")
            st.write(f"- æœ€ç§¯ææ—¥æœŸï¼š{max_sentiment_date}ï¼ˆå¾—åˆ†ï¼š{daily_sentiment_trend[max_sentiment_date]:.4f}ï¼‰")
            st.write(f"- æœ€æ¶ˆææ—¥æœŸï¼š{min_sentiment_date}ï¼ˆå¾—åˆ†ï¼š{daily_sentiment_trend[min_sentiment_date]:.4f}ï¼‰")
            
    except Exception as e:
        st.error(f'å±•ç¤ºå…¸å‹è¯„è®ºæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
        st.write('è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')

except Exception as e:
    st.error(f'åº”ç”¨ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}')
    st.write('è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œæˆ–å°è¯•è°ƒæ•´å‚æ•°ã€‚')

# é¡µè„š
st.markdown("---")
st.markdown("### å…³äº")
st.markdown("æœ¬åº”ç”¨åŸºäºä¸œæ–¹è´¢å¯Œè‚¡å§è¯„è®ºæ•°æ®ï¼Œä½¿ç”¨æƒ…æ„Ÿåˆ†ææŠ€æœ¯åˆ†ææŠ•èµ„è€…æƒ…ç»ªä¸è‚¡ç¥¨æ”¶ç›Šç‡ä¹‹é—´çš„å…³ç³»ã€‚")
st.markdown("æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œè‚¡å§ã€è‚¡ç¥¨ä»·æ ¼æ•°æ®")
st.markdown("æŠ€æœ¯æ ˆï¼šPythonã€Streamlitã€Pandasã€Scikit-learn")
